{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different classifiers on data of KdV patients and ID controls\n",
    "Overview of this notebook:\n",
    "\n",
    "First the deepface representations of the cropped images are read in from an Excel file. The data is then plotted by using either t-sne or PCA for dimension reduction. It is clear that there aren't two clear clusters.\n",
    "\n",
    "In the rest of the notebook the following classifiers are tested: k-NN, SVM, Random Forest, Gradient Boosting, AdaBoost, Gaussian Naive Bayes. In the end also an ensemble of all these methods or some of them is tried. None outperforming the Gradient Boosting classifier. \n",
    "\n",
    "To normalize the data either Normalizer (unit form) or StandardScaler (z = (x - mean)/std) is used, without any specific difference in performance yet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from os.path import join \n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rep(kdv_csv, ID_csv):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, csv_file in enumerate([ID_csv, kdv_csv]):\n",
    "        with open (csv_file, newline='') as file:\n",
    "            reader = csv.reader(file, delimiter=',')\n",
    "            for row in reader:\n",
    "                rep = list(map(float, row[1:]))\n",
    "                data.append(rep)\n",
    "                labels.append(i)\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_tsne(data, labels, lowest_age = -1, highest_age = -1):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot([1,2])\n",
    "\n",
    "    # visualize data in tnse (men/women)\n",
    "    X_embedded_tsne = TSNE(n_components=2, init='pca').fit_transform(data)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    unique = list(set(labels))\n",
    "    colors = [plt.cm.jet(float(i)/max(unique)) for i in unique]\n",
    "    for i, u in enumerate(unique):\n",
    "        xi = [X_embedded_tsne[j, 0] for j  in range(len(X_embedded_tsne[:,0])) if labels[j] == u]\n",
    "        yi = [X_embedded_tsne[j, 1] for j  in range(len(X_embedded_tsne[:,1])) if labels[j] == u]\n",
    "        plt.scatter(xi, yi, c=[colors[i]], label=str(u))\n",
    "    plt.legend()\n",
    "    plt.title(\"t-sne for age range {}-{}\".format(lowest_age, highest_age))\n",
    "\n",
    "    # visualize data in pca (men/women)\n",
    "    X_embedded_pca = PCA(n_components=2).fit_transform(data)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    unique = list(set(labels))\n",
    "    colors = [plt.cm.jet(float(i)/max(unique)) for i in unique]\n",
    "    for i, u in enumerate(unique):\n",
    "        xi = [X_embedded_pca[j, 0] for j  in range(len(X_embedded_pca[:,0])) if labels[j] == u]\n",
    "        yi = [X_embedded_pca[j, 1] for j  in range(len(X_embedded_pca[:,1])) if labels[j] == u]\n",
    "        plt.scatter(xi, yi, c=[colors[i]], label=str(u))\n",
    "    plt.legend()\n",
    "    plt.title(\"pca for age range{}-{}\".format(lowest_age, highest_age))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred): \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    plt.figure(1, figsize=(12,6))\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.5, label='LOOCV ROC (AUC = %0.2f)' % (roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='Chance level', alpha=.8)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_loo(model, data, labels):\n",
    "    all_y, all_probs, all_preds = [], [], [] \n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    for train, test in loo.split(data):\n",
    "        all_y.append(labels[test])\n",
    "        model = model.fit(data[train], labels[train])\n",
    "        all_probs.append(model.predict_proba(data[test].reshape(1, -1))[:,1])\n",
    "        all_preds.append(model.predict(data[test].reshape(1, -1)))\n",
    "        \n",
    "    aroc = roc_auc_score(all_y, all_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_y, all_preds).ravel()\n",
    "    spec = tn / (tn+fp)  \n",
    "    sens = tp / (tp+fn) \n",
    "    \n",
    "    return aroc, spec, sens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, i):\n",
    "\n",
    "    if i == 0:\n",
    "        return data\n",
    "    \n",
    "    if i == 1:\n",
    "        return Normalizer().fit_transform(data)\n",
    "        \n",
    "    if i == 2:\n",
    "        return StandardScaler().fit_transform(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classifier(data, labels):\n",
    "    best_aroc = 0\n",
    "    estimators = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    best_estimator_rf = 0\n",
    "    best_norm = -1\n",
    "    \n",
    "    trees = 60\n",
    "\n",
    "        \n",
    "    data = Normalizer().fit_transform(data)\n",
    "\n",
    "    # split train and test data\n",
    "    print(\"Confusion matrix with 10% test data\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=42)\n",
    "    print(\"Shape of train data: {} and shape of test data: {}\".format(X_train.shape, X_test.shape))\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=trees)\n",
    "    model = model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "    plot_confusion_matrix(model, X_test, y_test)\n",
    "    plt.show()\n",
    "\n",
    "    # print(\"Tn: {}, fp: {}, fn: {}, tp: {}\".format(tn, fp, fn , tp))\n",
    "    spec = tn / (tn+fp)  \n",
    "    sens = tp / (tp+fn) \n",
    "    print(\"Specificity: {}\".format(spec))\n",
    "    print(\"Sensitivity: {}\\n\\n\".format(sens))\n",
    "    \n",
    "    counter = 0\n",
    "    loo = LeaveOneOut()\n",
    "\n",
    "    all_y = [] # y_true\n",
    "    all_preds = [] # y_pred\n",
    "    for train, test in loo.split(data):\n",
    "        all_y.append(labels[test])\n",
    "        model = RandomForestClassifier(n_estimators=trees)\n",
    "\n",
    "        model = model.fit(data[train], labels[train])\n",
    "        all_preds.append(model.predict(data[test].reshape(1, -1)))\n",
    "        counter+=1\n",
    "        \n",
    "    print(\"amount of leave one out: {}\".format(counter))\n",
    "    print(\"amount of samples: {}\".format(data.shape))\n",
    "\n",
    "\n",
    "    \n",
    "    return best_estimator_rf, best_norm, best_aroc, best_spec, best_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(data_df, labels_df, data_dlib, labels_dlib, data_combination, nr_feats):\n",
    "    # assert data has same shape and labels are exactly the same\n",
    "    assert data_df.shape[0] == data_dlib.shape[0]\n",
    "    assert labels_df.shape == labels_dlib.shape\n",
    "    match = [True for i, j in zip(labels_df, labels_dlib) if i == j]\n",
    "    assert False not in match\n",
    "                \n",
    "                \n",
    "    if data_combination == 2 or data_combination == 3 or data_combination == 4:\n",
    "        # deepface + dlib (all features) \n",
    "        data, labels  = [], []\n",
    "        for index, (df_i, dlib_i) in enumerate(zip(data_df, data_dlib)):\n",
    "            if len(dlib_i) == 2210: \n",
    "                #only if a face is found (otherwise there a fewer zeros)\n",
    "                data.append(df_i.tolist()+dlib_i) # concatenation of 4096 deepface + 2210 dlib\n",
    "                labels.append(labels_df[index])\n",
    "                \n",
    "                                               \n",
    "    if data_combination == 3:\n",
    "        # deepface + dlib (x most important features)\n",
    "        # data, labels are already filled from the above if statement\n",
    "                                               \n",
    "        # using a Random Forest the x most important features are used                                   \n",
    "        forest = RandomForestClassifier(n_estimators=10,random_state=0) # 10 has been found with best aroc scores\n",
    "        forest.fit(data, labels)\n",
    "        importances = forest.feature_importances_\n",
    "        std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n",
    "        indices = np.argsort(importances)[::-1]\n",
    "        indices = indices[0:nr_feats] # get 100 most important features\n",
    "\n",
    "        data2 = []\n",
    "        for row in data:\n",
    "            data2.append(np.array(row)[indices])                                \n",
    "        data = data2\n",
    "   \n",
    "    return 0, np.array(data), np.array(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data is: (144, 200)\n",
      "\n",
      "Confusion matrix with 10% test data\n",
      "Shape of train data: (129, 200) and shape of test data: (15, 200)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity: 0.5714285714285714\n",
      "Sensitivity: 0.75\n",
      "\n",
      "\n",
      "amount of leave one out: 144\n",
      "amount of samples: (144, 200)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_spec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-b64a7b392492>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done running main file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-b64a7b392492>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;31m#results_file.write(\"CLASSIFIER RESULTS for kdv-control age group \" + str(low_age) + \"-\" + str(high_age) + \"\\n\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[0mn_trees_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_aroc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_sens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-69-6d9d55d92aa7>\u001b[0m in \u001b[0;36mrf_classifier\u001b[1;34m(data, labels)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_estimator_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_aroc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_sens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'best_spec' is not defined"
     ]
    }
   ],
   "source": [
    "def main():    \n",
    "    \n",
    "    today = date.today()\n",
    "    start = time.time()\n",
    "    \n",
    "    data_dir = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\kdv\\representations\\\\\"\n",
    "    #results_file = open(\"results/kdv-results-\" + str(today)+\".txt\", \"w\")\n",
    "\n",
    "    nr_feats = 200\n",
    "    \n",
    "    ### NOTHING NEEDS TO BE EDITED BELOW ###\n",
    "    \n",
    "    for data_combination in [3]:\n",
    "        \n",
    "        #results_file.write(get_header(data_combination, nr_feats))\n",
    "            \n",
    "        age_ranges = [[1, 40]] # [[1, 3], [4, 16], [17, 40], [1, 40]] \n",
    "\n",
    "        for [low_age, high_age] in age_ranges:\n",
    "\n",
    "            method = \"dlib\"\n",
    "            kdv_csv = data_dir+\"\\kdv-patients-\"+method+\"-cropped-age-group-\"+str(low_age)+\"-\"+str(high_age)+\".csv\"  \n",
    "            ID_csv  = data_dir+\"\\ID-controls-\"+method+\"-cropped-age-group-\"+str(low_age)+\"-\"+str(high_age)+\".csv\"\n",
    "            data_dlib, labels_dlib = read_rep(kdv_csv, ID_csv)\n",
    "\n",
    "            method = \"deepface\"\n",
    "            kdv_csv = data_dir+\"\\kdv-patients-\"+method+\"-cropped-age-group-\"+str(low_age)+\"-\"+str(high_age)+\".csv\"  \n",
    "            ID_csv  = data_dir+\"ID-controls-\"+method+\"-cropped-age-group-\"+str(low_age)+\"-\"+str(high_age)+\".csv\"\n",
    "            data_df, labels_df = read_rep(kdv_csv, ID_csv)\n",
    "\n",
    "            \n",
    "            # data, labels depend on data_combination\n",
    "            nr_comps, data, labels = concatenate(data_df, labels_df, data_dlib, labels_dlib, data_combination, nr_feats)\n",
    "            \n",
    "            print(\"Shape of the data is: {}\\n\".format(data.shape))\n",
    "\n",
    "            if data_combination == 4:\n",
    "                results_file.write(\"Nr of pca components used: {}\\n\".format(nr_comps))\n",
    "\n",
    "\n",
    "            # plot representation\n",
    "            # plot_pca_tsne(data, labels, low_age, high_age)\n",
    "\n",
    "            #results_file.write(\"CLASSIFIER RESULTS for kdv-control age group \" + str(low_age) + \"-\" + str(high_age) + \"\\n\")\n",
    "\n",
    "            n_trees_rf, rf_norm, rf_aroc, rf_spec, rf_sens = rf_classifier(data, labels)\n",
    "            break\n",
    "            \n",
    "            results_file.write(\"Random Forest classifier (trees = {}), normalize : {} \\n    AROC: {:.4f}, spec: {:.4f}, sens: {:.4f}\\n\".format(n_trees_rf, rf_norm, rf_aroc, rf_spec, rf_sens))\n",
    "\n",
    "#             n_trees_gr, gr_norm, gr_aroc, gr_spec, gr_sens = gr_classifier(data, labels)\n",
    "#             results_file.write(\"Gradient Boost classifier (trees = {}), normalize : {} \\n    AROC: {:.4f}, spec: {:.4f}, sens: {:.4f}\\n\".format(n_trees_gr, gr_norm, gr_aroc, gr_spec, gr_sens))\n",
    "\n",
    "#             n_trees_ada, ada_norm, ada_aroc, ada_spec, ada_sens = ada_classifier(data, labels)\n",
    "#             results_file.write(\"Ada Boost classifier (trees = {}), normalize : {} \\n    AROC: {:.4f}, spec: {:.4f}, sens: {:.4f}\\n\".format(n_trees_ada, ada_norm, ada_aroc, ada_spec, ada_sens))\n",
    "\n",
    "            results_file.write(\"\\n\")\n",
    "\n",
    "    end = time.time()\n",
    "    results_file.write(\"Running this whole file took {} seconds\".format(end-start))\n",
    "    results_file.close()\n",
    "    print(\"done running main file\")\n",
    "    \n",
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7: VotingClassifier with GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/rmferg/soft-voting-classifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "t0 = time.clock()\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=1)\n",
    "svm = SVC(probability=True, kernel='rbf')\n",
    "knn = KNeighborsClassifier(p=2, metric='minkowski')\n",
    "nb = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('tree', tree), ('svm', svm), ('knn', knn),('nb', nb)], voting='soft')\n",
    "\n",
    "param_range10 = [.001, .01, 1, 10, 100]\n",
    "param_range1 = list(range(3, 8))\n",
    "param_grid = [{'svm__C':param_range10, 'svm__gamma':param_range10, 'tree__max_depth':param_range1, \n",
    "               'knn__n_neighbors':param_range1}]\n",
    "\n",
    "gs = GridSearchCV(estimator=eclf, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "gs = gs.fit(X_train_std, y_train)\n",
    "\n",
    "print('Best accuracy score: %.3f \\nBest parameters: %s' % (gs.best_score_, gs.best_params_))\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train_std, y_train)\n",
    "t1 = time.clock()\n",
    "print('Running time: %.3f' % (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "print('ROC AUC: %.3f \\nAccuracy: %.3f \\nConfusion Matrix:' % (roc_auc_score(y_true=y_test, y_score=y_pred),\n",
    "                                         accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
