{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of DeepFace using Keras\n",
    "In this notebook a [Keras implementation](https://github.com/swghosh/DeepFace) from Github of Facebook's [DeepFace](https://research.fb.com/publications/deepface-closing-the-gap-to-human-level-performance-in-face-verification/) is loaded and used. The weights are trained on the publicly available VGG dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from os import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image \n",
    "from keras.models import Model\n",
    "import tensorflow\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement model architecture\n",
    "\n",
    "IMAGE_SIZE = (152, 152) # set by the model \n",
    "CHANNELS = 3 # RGB image\n",
    "NUM_CLASSES = 8631 # classification layer will be removed \n",
    "LEARN_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "def create_classifying_deepface(image_size=IMAGE_SIZE, channels=CHANNELS, num_classes=NUM_CLASSES, learn_rate=LEARN_RATE, momentum=MOMENTUM):\n",
    "    \"\"\"\n",
    "    Deep CNN architecture primarily for Face Recognition,\n",
    "    Face Verification and Face Representation (feature extraction) purposes\n",
    "    \"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\"\n",
    "    CNN architecture proposed by Taigman et al. (CVPR 2014)\n",
    "    \"\"\"\n",
    "\n",
    "    wt_init = keras.initializers.RandomNormal(mean=0, stddev=0.01)\n",
    "    bias_init = keras.initializers.Constant(value=0.5)\n",
    "\n",
    "    \"\"\"\n",
    "    Construct certain functions \n",
    "    for using some common parameters\n",
    "    with network layers\n",
    "    \"\"\"\n",
    "    def conv2d_layer(**args):\n",
    "        return keras.layers.Conv2D(**args, \n",
    "            kernel_initializer=wt_init, \n",
    "            bias_initializer=bias_init,\n",
    "            activation=keras.activations.relu)\n",
    "    def lc2d_layer(**args):\n",
    "        return keras.layers.LocallyConnected2D(**args, \n",
    "            kernel_initializer=wt_init, \n",
    "            bias_initializer=bias_init,\n",
    "            activation=keras.activations.relu)\n",
    "    def dense_layer(**args):\n",
    "        return keras.layers.Dense(**args, \n",
    "            kernel_initializer=wt_init, \n",
    "            bias_initializer=bias_init)\n",
    "\n",
    "    \"\"\"\n",
    "    Create the network using\n",
    "    tf.keras.layers.Layer(s)\n",
    "    \"\"\"\n",
    "    deepface = keras.models.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(*image_size, channels), name='I0'),\n",
    "        conv2d_layer(filters=32, kernel_size=11, name='C1'),\n",
    "        keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same',  name='M2'),\n",
    "        conv2d_layer(filters=16, kernel_size=9, name='C3'),\n",
    "        lc2d_layer(filters=16, kernel_size=9, name='L4'),\n",
    "        lc2d_layer(filters=16, kernel_size=7, strides=2, name='L5'),\n",
    "        lc2d_layer(filters=16, kernel_size=5, name='L6'),\n",
    "        keras.layers.Flatten(name='F0'),\n",
    "        dense_layer(units=4096, activation=keras.activations.relu, name='F7'),\n",
    "        keras.layers.Dropout(rate=0.5, name='D0'),\n",
    "        dense_layer(units=num_classes, activation=keras.activations.softmax, name='F8')\n",
    "    ], name='DeepFace')\n",
    "    # deepface.summary()\n",
    "\n",
    "    \"\"\"\n",
    "    A tf.keras.optimizers.SGD will\n",
    "    be used for training,\n",
    "    and compile the model\n",
    "    \"\"\"\n",
    "    sgd_opt = keras.optimizers.SGD(lr=learn_rate, momentum=momentum)\n",
    "    cce_loss = keras.losses.categorical_crossentropy\n",
    "\n",
    "    deepface.compile(optimizer=sgd_opt, loss=cce_loss, metrics=['accuracy'])\n",
    "    \n",
    "    return deepface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_PATH = 'https://github.com/swghosh/DeepFace/releases/download/weights-vggface2-2d-aligned/VGGFace2_DeepFace_weights_val-0.9034.h5.zip'\n",
    "MD5_HASH = '0b21fb70cd6901c96c19ac14c9ea8b89'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights():\n",
    "    filename = 'deepface.zip'\n",
    "    downloaded_file_path = keras.utils.get_file(filename, DOWNLOAD_PATH, \n",
    "        md5_hash=MD5_HASH, extract=True)\n",
    "    downloaded_h5_file = path.join(path.dirname(downloaded_file_path), \n",
    "        path.basename(DOWNLOAD_PATH).rstrip('.zip'))\n",
    "    return downloaded_h5_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deepface():\n",
    "    model = create_classifying_deepface()\n",
    "    weights = get_weights()\n",
    "    model.load_weights(weights)\n",
    "    model2 = Model(model.input, model.layers[-2].output)\n",
    "    model2.summary()\n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "I0 (InputLayer)              (None, 152, 152, 3)       0         \n",
      "_________________________________________________________________\n",
      "C1 (Conv2D)                  (None, 142, 142, 32)      11648     \n",
      "_________________________________________________________________\n",
      "M2 (MaxPooling2D)            (None, 71, 71, 32)        0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 63, 63, 16)        41488     \n",
      "_________________________________________________________________\n",
      "L4 (LocallyConnected2D)      (None, 55, 55, 16)        62774800  \n",
      "_________________________________________________________________\n",
      "L5 (LocallyConnected2D)      (None, 25, 25, 16)        7850000   \n",
      "_________________________________________________________________\n",
      "L6 (LocallyConnected2D)      (None, 21, 21, 16)        2829456   \n",
      "_________________________________________________________________\n",
      "F0 (Flatten)                 (None, 7056)              0         \n",
      "_________________________________________________________________\n",
      "F7 (Dense)                   (None, 4096)              28905472  \n",
      "_________________________________________________________________\n",
      "D0 (Dropout)                 (None, 4096)              0         \n",
      "=================================================================\n",
      "Total params: 102,412,864\n",
      "Trainable params: 102,412,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_deepface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to put an image through the model \n",
    "The image needs to be resized to the above defined size to be able to put through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 19/19 [00:27<00:00,  1.45s/it]\n",
      "100%|██████████████████████████████████████████| 19/19 [00:01<00:00, 11.34it/s]\n"
     ]
    }
   ],
   "source": [
    "syn_name = \"SON\"\n",
    "data_dir = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\{}\".format(syn_name)\n",
    "\n",
    "age_ranges = [[1, 100]] # [[1, 3], [4, 16], [17, 40]]\n",
    "syn_rep = []\n",
    "ID_rep = []\n",
    "\n",
    "    \n",
    "for [low_age, high_age] in age_ranges:\n",
    "    \n",
    "    # open directories\n",
    "    #kdv_dir = data_dir + \"\\kdv-patients-age-group-\"+str(low_age) + \"-\" + str(high_age)\n",
    "    #ID_dir = data_dir + \"\\kdv-selected-ID-controls-age-group-\"+str(low_age) + \"-\" + str(high_age)\n",
    "    \n",
    "    syn_dir = data_dir + \"\\{}-patients\".format(syn_name)\n",
    "    ID_dir = data_dir + \"\\{}-selected-ID-controls\".format(syn_name)\n",
    "    \n",
    "    # get list of filenames\n",
    "    files_syn = [f for f in listdir(syn_dir) if (isfile(join(syn_dir, f)))and syn_name in f]\n",
    "    files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f))) and \".JPG\" in f or \".jpg\" in f]\n",
    "\n",
    "#     print(len(files_syn))\n",
    "#     print(len(files_ID))\n",
    "\n",
    "    # for each kdv image save deepface rep as list:\n",
    "    for filename in tqdm(files_syn):\n",
    "        im = Image.open(join(syn_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        output = model.predict(np.expand_dims(im, axis=0))\n",
    "        syn_rep.append([filename] + output[0].tolist())  \n",
    "    \n",
    "\n",
    "    # for each ID image save deepface rep as list:\n",
    "    for filename in tqdm(files_ID):\n",
    "        im = Image.open(join(ID_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        output = model.predict(np.expand_dims(im, axis=0))\n",
    "        ID_rep.append([filename] + output[0].tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(syn_rep))\n",
    "print(len(ID_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with saving all deepface representations.\n"
     ]
    }
   ],
   "source": [
    "# location to save representation\n",
    "csv_file_syn = data_dir+ \"\\\\representations\\{}-patients-deepface.csv\".format(syn_name)\n",
    "csv_file_ID = data_dir+ \"\\\\representations\\ID-controls-deepface.csv\"\n",
    "\n",
    "# save representation of kdv patients\n",
    "with open(csv_file_syn, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(syn_rep)\n",
    "\n",
    "# save representation of ID controls\n",
    "with open(csv_file_ID, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(ID_rep)\n",
    "\n",
    "print(\"Done with saving all deepface representations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
