{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different classifiers on data of KdV patients and ID controls\n",
    "Overview of this notebook:\n",
    "\n",
    "First the deepface representations of the cropped images are read in from an Excel file. The data is then plotted by using either t-sne or PCA for dimension reduction. It is clear that there aren't two clear clusters.\n",
    "\n",
    "In the rest of the notebook the following classifiers are tested: k-NN, SVM, Random Forest, Gradient Boosting, AdaBoost, Gaussian Naive Bayes. In the end also an ensemble of all these methods or some of them is tried. None outperforming the Gradient Boosting classifier. \n",
    "\n",
    "To normalize the data either Normalizer (unit form) or StandardScaler (z = (x - mean)/std) is used, without any specific difference in performance yet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dlib_rep(kdv_csv, ID_csv):\n",
    "    data = []\n",
    "    labels = []\n",
    "    no_rep = []\n",
    "    \n",
    "    # get the representations from Excel files kdv\n",
    "    with open (kdv_csv, newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for i, row in enumerate(reader):\n",
    "            rep = list(map(float, row[1:]))\n",
    "#             if all(v == 0 for v in rep):\n",
    "#                 no_rep.append(i)\n",
    "#             else:\n",
    "            data.append(rep)\n",
    "            labels.append(1)\n",
    "\n",
    "    # get the representations from Excel files ID control\n",
    "    with open (ID_csv, newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for i, row in enumerate(reader):\n",
    "#             if i not in no_rep: \n",
    "#                 rep = list(map(float, row[1:]))\n",
    "            data.append(rep)\n",
    "            labels.append(0)\n",
    "\n",
    "    #print(\"All image representations are read in.\")\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_deepface_rep(kdv_csv, ID_csv):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    # get the representations from Excel files kdv\n",
    "    with open (kdv_csv, newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for row in reader:\n",
    "            rep = list(map(float, row[1:]))\n",
    "            data.append(rep)\n",
    "            labels.append(1)\n",
    "\n",
    "    # get the representations from Excel files ID control\n",
    "    with open (ID_csv, newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for row in reader:\n",
    "            rep = list(map(float, row[1:]))\n",
    "            data.append(rep)\n",
    "            labels.append(0)\n",
    "\n",
    "    #print(\"All image representations are read in.\")\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_tsne(data, labels, lowest_age = -1, highest_age = -1):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot([1,2])\n",
    "\n",
    "    # visualize data in tnse (men/women)\n",
    "    X_embedded_tsne = TSNE(n_components=2, init='pca').fit_transform(data)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    unique = list(set(labels))\n",
    "    colors = [plt.cm.jet(float(i)/max(unique)) for i in unique]\n",
    "    for i, u in enumerate(unique):\n",
    "        xi = [X_embedded_tsne[j, 0] for j  in range(len(X_embedded_tsne[:,0])) if labels[j] == u]\n",
    "        yi = [X_embedded_tsne[j, 1] for j  in range(len(X_embedded_tsne[:,1])) if labels[j] == u]\n",
    "        plt.scatter(xi, yi, c=[colors[i]], label=str(u))\n",
    "    plt.legend()\n",
    "    plt.title(\"t-sne for age range {}-{}\".format(lowest_age, highest_age))\n",
    "\n",
    "    # visualize data in pca (men/women)\n",
    "    X_embedded_pca = PCA(n_components=2).fit_transform(data)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    unique = list(set(labels))\n",
    "    colors = [plt.cm.jet(float(i)/max(unique)) for i in unique]\n",
    "    for i, u in enumerate(unique):\n",
    "        xi = [X_embedded_pca[j, 0] for j  in range(len(X_embedded_pca[:,0])) if labels[j] == u]\n",
    "        yi = [X_embedded_pca[j, 1] for j  in range(len(X_embedded_pca[:,1])) if labels[j] == u]\n",
    "        plt.scatter(xi, yi, c=[colors[i]], label=str(u))\n",
    "    plt.legend()\n",
    "    plt.title(\"pca for age range{}-{}\".format(lowest_age, highest_age))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred): \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    plt.figure(1, figsize=(12,6))\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.5, label='LOOCV ROC (AUC = %0.2f)' % (roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='Chance level', alpha=.8)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_loo(model, data, labels):\n",
    "    all_y = []\n",
    "    all_probs = []\n",
    "    all_preds = []\n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    for train, test in loo.split(data):\n",
    "        all_y.append(labels[test])\n",
    "        model = model.fit(data[train], labels[train])\n",
    "        all_probs.append(model.predict_proba(data[test].reshape(1, -1))[:,1])\n",
    "        all_preds.append(model.predict(data[test].reshape(1, -1)))\n",
    "        \n",
    "    aroc = roc_auc_score(all_y, all_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_y, all_preds).ravel()\n",
    "    spec = tn / (tn+fp)  \n",
    "    sens = tp / (tp+fn) \n",
    "    \n",
    "    return aroc, spec, sens "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_classifier(data, labels):\n",
    "    k_values = [3,4,5,6,7,8,9,10,11,12,13,14,15]\n",
    "    best_aroc = 0\n",
    "    best_k = 0\n",
    "\n",
    "    for k in tqdm(k_values):\n",
    "        for normalize in [0, 1, 2]:\n",
    "            \n",
    "            model = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "            aroc, spec, sens = calculate_metrics_loo(model, data, labels)\n",
    "           \n",
    "            if aroc > best_aroc:\n",
    "                best_aroc, best_spec, best_sens, best_norm = aroc, spec, sens, normalize \n",
    "                best_k = k\n",
    "                \n",
    "    return best_k, best_norm, best_aroc, best_spec, best_sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_classifier(data, labels):\n",
    "    kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "    best_aroc = 0\n",
    "    best_kernel = None\n",
    "\n",
    "    for k in tqdm(kernels):\n",
    "        for normalize in [0, 1, 2]:\n",
    "            \n",
    "            model = SVC(kernel=k, probability=True)\n",
    "            aroc, spec, sens = calculate_metrics_loo(model, data, labels)\n",
    "           \n",
    "            if aroc > best_aroc:\n",
    "                best_aroc, best_spec, best_sens, best_norm = aroc, spec, sens, normalize \n",
    "                best_kernel = k\n",
    "                \n",
    "    return best_kernel, best_norm, best_aroc, best_spec, best_sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 4: Gradient Boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr_classifier(data, labels):\n",
    "    best_aroc = 0\n",
    "    estimators = [5, 10, 20, 40, 60, 80, 100]\n",
    "    best_estimator_gr = 0\n",
    "    best_norm = -1\n",
    "\n",
    "    for est in tqdm(estimators):\n",
    "        for normalize in [0, 1, 2]:\n",
    "            \n",
    "            model = GradientBoostingClassifier(n_estimators=est, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "            aroc, spec, sens = calculate_metrics_loo(model, data, labels)\n",
    "           \n",
    "            if aroc > best_aroc:\n",
    "                best_aroc, best_spec, best_sens, best_norm = aroc, spec, sens, normalize \n",
    "                best_estimator_gr = est\n",
    "                \n",
    "    return best_estimator_gr, best_norm, best_aroc, best_spec, best_sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 5: AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_classifier(data, labels):\n",
    "    best_aroc = 0\n",
    "    estimators = [5, 10, 20, 40, 60, 80, 100]\n",
    "    best_estimator_ada = 0\n",
    "    best_norm = -1\n",
    "\n",
    "    for est in tqdm(estimators):\n",
    "        for normalize in [0,1, 2]:\n",
    "\n",
    "            model = AdaBoostClassifier(n_estimators=est, random_state=0)\n",
    "            aroc, spec, sens = calculate_metrics_loo(model, data, labels)\n",
    "           \n",
    "            if aroc > best_aroc:\n",
    "                best_aroc, best_spec, best_sens, best_norm = aroc, spec, sens, normalize \n",
    "                best_estimator_ada = est\n",
    "                \n",
    "    return best_estimator_ada, best_norm, best_aroc, best_spec, best_sens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 6: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_classifier(data, labels):\n",
    "    best_aroc = 0\n",
    "    best_norm = -1\n",
    "\n",
    "    for normalize in tqdm([0,1, 2]):\n",
    "        model = GaussianNB()\n",
    "        aroc, spec, sens = calculate_metrics_loo(model, data, labels)\n",
    "\n",
    "        if aroc > best_aroc:\n",
    "            best_aroc, best_spec, best_sens, best_norm = aroc, spec, sens, normalize \n",
    "                \n",
    "    return best_norm, best_aroc, best_spec, best_sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7: Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_classifiers(k, kernel, n_trees_rf, n_trees_gr, n_trees_ada, data, labels):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance')\n",
    "    svm = SVC(kernel=kernel, probability=True)\n",
    "    random_forest = RandomForestClassifier(n_estimators=n_trees_rf) \n",
    "    gr_clf = GradientBoostingClassifier(n_estimators=n_trees_gr, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "    ada_clf = AdaBoostClassifier(n_estimators=n_trees_ada, random_state=0)\n",
    "    nb = GaussianNB()\n",
    "\n",
    "    classifiers = [('knn', knn), ('svm', svm),('gr_clf', gr_clf), ('random_forest', random_forest), ('nb', nb), ('ada_clf', ada_clf)]\n",
    "    \n",
    "    cv = int(len(labels)/2)\n",
    "\n",
    "    classifier_combinations = []\n",
    "    for L in range(1, len(classifiers)+1):\n",
    "        for subset in itertools.combinations(classifiers, L):\n",
    "            classifier_combinations.append(subset)\n",
    "    \n",
    "    best_ensemble_acc = 0\n",
    "    best_classifier_com = None\n",
    "    best_norm = -1\n",
    "    best_vote = None\n",
    "\n",
    "    for classifier_com in classifier_combinations:\n",
    "    #for classifier_com in tqdm(classifier_combinations):\n",
    "        \n",
    "        for normalize in [0, 1, 2]:\n",
    "            for vote_sort in ['soft', 'hard']:\n",
    "\n",
    "                weights = np.ones(len(classifier_com)).tolist()\n",
    "                ensemble_clf = VotingClassifier(estimators=classifier_com,\n",
    "                                        voting=vote_sort,\n",
    "                                        weights=weights)\n",
    "                \n",
    "                            \n",
    "                mean_acc = cross_val_classifier(ensemble_clf, data, labels, normalize)\n",
    "                \n",
    "                clf_string = \"\"\n",
    "                for clf in classifier_com:\n",
    "                    clf_string  = clf_string + \" \" + clf[0]\n",
    "                    \n",
    "                print(\"Ensemble: {}\".format(clf_string))\n",
    "                print(\"With accuracy: {}\".format(mean_acc))\n",
    "                \n",
    "                if mean_acc > best_ensemble_acc:\n",
    "                    best_ensemble_acc = mean_acc\n",
    "                    best_norm = normalize\n",
    "                    best_vote = vote_sort\n",
    "                    best_classifier_com = classifier_com\n",
    "    \n",
    "    return best_ensemble_acc, best_classifier_com, best_vote, best_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(data_df, labels_df, data_dlib, labels_dlib):\n",
    "    assert data_df.shape[0] == data_dlib.shape[0]\n",
    "    assert labels_df.shape == labels_dlib.shape\n",
    "    \n",
    "    match = [True for i, j in zip(labels_df, labels_dlib) if i == j]\n",
    "    \n",
    "    if False not in match:\n",
    "        print(\"labels are the same\")\n",
    "    else:\n",
    "        print(\"labels are not the same\")\n",
    "\n",
    "        \n",
    "    # zip lists; if shape of dlib is 2210 instead of 11, concatenate them, otherwise skip them\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    for index, (df_i, dlib_i) in enumerate(zip(data_df, data_dlib)):\n",
    "        if len(dlib_i) == 2210:\n",
    "            data.append(df_i.tolist()+dlib_i)\n",
    "            labels.append(labels_df[index])\n",
    "            \n",
    "#     for i in range(0, 100):\n",
    "#         pca = PCA(n_components=i)\n",
    "#         components = pca.fit_transform(data)    \n",
    "#         if sum(pca.explained_variance_ratio_) > 0.9:\n",
    "#             #best_com = i\n",
    "#             break\n",
    "        \n",
    "    #pca = PCA(n_components=best_com)\n",
    "    #components = pca.fit_transform(data)            \n",
    "    \n",
    "#    print(\"Explained variance with {} components: {:.3f}%\".format(components.shape[1], sum(pca.explained_variance_ratio_)*100))\n",
    "    \n",
    "#    return components.shape[1], np.array(components), np.array(labels)\n",
    "    return 0, np.array(data), np.array(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classifier(data, labels):\n",
    "    best_aroc = 0\n",
    "    estimators = [5, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
    "    best_estimator_rf = 0\n",
    "    best_norm = -1\n",
    "\n",
    "    for est in tqdm(estimators):\n",
    "        for normalize in [0, 1, 2]:\n",
    "            \n",
    "            model = RandomForestClassifier(n_estimators=est)\n",
    "            aroc, spec, sens = calculate_metrics_loo(model, data, labels)\n",
    "           \n",
    "            if aroc > best_aroc:\n",
    "                best_aroc, best_spec, best_sens, best_norm = aroc, spec, sens, normalize \n",
    "                best_estimator_rf = est\n",
    "    \n",
    "#     # Getting the feature importance \n",
    "#     forest = RandomForestClassifier(n_estimators=10,random_state=0)\n",
    "#     forest.fit(data, labels)\n",
    "#     importances = forest.feature_importances_\n",
    "#     std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n",
    "#     indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "#     # Print the feature ranking\n",
    "#     print(\"Feature ranking:\")\n",
    "\n",
    "#     for f in range(data.shape[1]):\n",
    "#         print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "#         if f == 20:\n",
    "#             break\n",
    "    \n",
    "#     indices = indices[0:25]\n",
    "\n",
    "#     # Plot the impurity-based feature importances of the forest\n",
    "#     plt.figure(figsize=(20, 10))\n",
    "#     plt.title(\"Feature importances\")\n",
    "#     plt.bar(range(25), importances[indices],\n",
    "#             color=\"r\", yerr=std[indices], align=\"center\")\n",
    "#     plt.xticks(range(25), indices)\n",
    "#     plt.xlim([-1, 25])\n",
    "#     #plt.show()\n",
    "#     plt.savefig(r\"C:\\Users\\manz616236\\Documents\\face-classification\\feature_importance_RF_10_dp-dlib.png\", dpi=100)\n",
    "    return best_estimator_rf, best_norm, best_aroc, best_spec, best_sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels are the same\n",
      "Feature ranking:\n",
      "1. feature 5455 (0.100000)\n",
      "2. feature 5377 (0.100000)\n",
      "3. feature 5264 (0.099165)\n",
      "4. feature 4454 (0.094570)\n",
      "5. feature 5280 (0.092003)\n",
      "6. feature 5282 (0.091958)\n",
      "7. feature 5284 (0.091895)\n",
      "8. feature 5375 (0.087027)\n",
      "9. feature 4248 (0.086999)\n",
      "10. feature 5442 (0.082316)\n",
      "11. feature 6212 (0.013105)\n",
      "12. feature 1950 (0.010656)\n",
      "13. feature 2538 (0.010260)\n",
      "14. feature 3471 (0.005430)\n",
      "15. feature 1385 (0.005414)\n",
      "16. feature 3658 (0.005318)\n",
      "17. feature 5496 (0.005280)\n",
      "18. feature 5904 (0.005257)\n",
      "19. feature 4260 (0.002787)\n",
      "20. feature 1150 (0.002762)\n",
      "21. feature 4506 (0.002741)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'best_spec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-86f18608c642>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"done running main file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-86f18608c642>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# print(\"Random Forest classifier:\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mn_trees_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_aroc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_sens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mresults_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Random Forest classifier (trees = {}), normalize : {} \\nspecificity: {}, sensitivity: {}, AROC: {} \\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_trees_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_sens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_aroc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-e4cac7d3ba74>\u001b[0m in \u001b[0;36mrf_classifier\u001b[1;34m(data, labels)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;31m#plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\manz616236\\Documents\\face-classification\\feature_importance_RF_10_dp-dlib.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_estimator_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_aroc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_spec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_sens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'best_spec' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():    \n",
    "    \n",
    "    today = date.today()\n",
    "    \n",
    "    #for method in [\"dlib\"]: #, \"deepface\"]:\n",
    "\n",
    "    #results_file = open(\"results/results_dlib-deepface_\" + str(today)+\".txt\", \"w\")\n",
    "\n",
    "    age_ranges = [[1, 40]] # [[1, 3], [4, 16], [17, 40], [1, 40]] \n",
    "\n",
    "    for [lowest_age, highest_age] in age_ranges:\n",
    "\n",
    "        method = \"dlib\"\n",
    "\n",
    "        kdv_csv = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\representations\\kdv-patients-\"+method+\"-cropped-age-group-\"+str(lowest_age)+\"-\"+str(highest_age)+\".csv\"    \n",
    "        ID_csv  = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\representations\\ID-controls-\"+method+\"-cropped-age-group-\"+str(lowest_age)+\"-\"+str(highest_age)+\".csv\"\n",
    "\n",
    "        data_dlib, labels_dlib = read_dlib_rep(kdv_csv, ID_csv)\n",
    "\n",
    "        method = \"deepface\"\n",
    "\n",
    "        kdv_csv = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\representations\\kdv-patients-\"+method+\"-cropped-age-group-\"+str(lowest_age)+\"-\"+str(highest_age)+\".csv\"    \n",
    "        ID_csv  = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\representations\\ID-controls-\"+method+\"-cropped-age-group-\"+str(lowest_age)+\"-\"+str(highest_age)+\".csv\"\n",
    "\n",
    "        data_df, labels_df = read_deepface_rep(kdv_csv, ID_csv)\n",
    "        #data, labels = read_deepface_rep(kdv_csv, ID_csv)\n",
    "        \n",
    "        # CHECK METHOD\n",
    "        #if method == \"dlib\":\n",
    "        #data_df, labels_df = read_deepface_rep(kdv_csv, ID_csv)\n",
    "        #if method ==\"deepface\":\n",
    "\n",
    "        nr_components, data, labels = concatenate(data_df, labels_df, data_dlib, labels_dlib)\n",
    "\n",
    "        # plot representation\n",
    "        #plot_pca_tsne(data, labels, lowest_age, highest_age)\n",
    "\n",
    "        # write results and also the parameters to a file \n",
    "        # print(\"Best accuracies to classify the age group \" + str(lowest_age) + \"-\" + str(highest_age))\n",
    "        # results_file.write(\"Classifier results for kdv-control age group \" + str(lowest_age) + \"-\" + str(highest_age) + \"\\n\")\n",
    "        #results_file.write(\"Nr of pca components used: {}\".format(nr_components))\n",
    "       \n",
    "        # apply classifiers\n",
    "        # print(\"K-NN classifier:\")\n",
    "        #k, knn_norm, knn_aroc, knn_spec, knn_sens = knn_classifier(data, labels)\n",
    "        #results_file.write(\"knn classifier (k = {}), normalize : {} \\nspecificity: {}, sensitivity: {}, AROC: {} \\n\".format(k, knn_norm, knn_spec, knn_sens, knn_aroc))\n",
    "\n",
    "        # print(\"SVM classifier:\")\n",
    "        #kernel, svm_norm, svm_aroc, svm_spec, svm_sens = svm_classifier(data, labels)\n",
    "        #results_file.write(\"svm classifier (k = {}), normalize : {} \\nspecificity: {}, sensitivity: {}, AROC: {} \\n\".format(kernel, svm_norm, svm_spec, svm_sens, svm_aroc))\n",
    "\n",
    "        # print(\"Random Forest classifier:\")\n",
    "        n_trees_rf, rf_norm, rf_aroc, rf_spec, rf_sens = rf_classifier(data, labels)\n",
    "        results_file.write(\"Random Forest classifier (trees = {}), normalize : {} \\nspecificity: {}, sensitivity: {}, AROC: {} \\n\".format(n_trees_rf, rf_norm, rf_spec, rf_sens, rf_aroc))\n",
    "        \n",
    "        break\n",
    "        \n",
    "        # print(\"Gradient Boost classifier:\")\n",
    "        n_trees_gr, gr_norm, gr_aroc, gr_spec, gr_sens = gr_classifier(data, labels)\n",
    "        results_file.write(\"Gradient Boost classifier (trees = {}), normalize : {} \\nspecificity: {}, sensitivity: {}, AROC: {} \\n\".format(n_trees_gr, gr_norm, gr_spec, gr_sens, gr_aroc))\n",
    "\n",
    "        # print(\"Ada Boost classifier:\")\n",
    "        n_trees_ada, ada_norm, ada_aroc, ada_spec, ada_sens = ada_classifier(data, labels)\n",
    "        results_file.write(\"Ada Boost classifier (trees = {}), normalize : {} \\nspecificity: {}, sensitivity: {}, AROC: {} \\n\".format(n_trees_ada, ada_norm, ada_spec, ada_sens, ada_aroc))\n",
    "\n",
    "#         ensemble_acc, clf_combination, best_vote, ensemble_norm = ensemble_classifiers(k, kernel, n_trees_rf, n_trees_gr, n_trees_ada, data, labels) \n",
    "#         print(\"ensemble classifier has acc: {:.3f} \\n with ensemble: {}\".format(ensemble_acc, str(clf_combination)))\n",
    "#         print(\"\\n \\n \\n\")\n",
    "\n",
    "#         results_file.write(\"ensemble classifier with acc: \" + str(ensemble_acc) + \" with the combination \" + str(clf_combination) + \" and best vote \" + str(best_vote) + \" and normalize = \" + str(ensemble_norm) + \"\\n\")\n",
    "#         results_file.write(\"\\n \\n \")  \n",
    "\n",
    "        results_file.write(\"\\n\")\n",
    "\n",
    "    results_file.close()\n",
    "    print(\"done running main file\")\n",
    "        \n",
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 7: VotingClassifier with GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/rmferg/soft-voting-classifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.1, random_state=1)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import time\n",
    "t0 = time.clock()\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=1)\n",
    "svm = SVC(probability=True, kernel='rbf')\n",
    "knn = KNeighborsClassifier(p=2, metric='minkowski')\n",
    "nb = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('tree', tree), ('svm', svm), ('knn', knn),('nb', nb)], voting='soft')\n",
    "\n",
    "param_range10 = [.001, .01, 1, 10, 100]\n",
    "param_range1 = list(range(3, 8))\n",
    "param_grid = [{'svm__C':param_range10, 'svm__gamma':param_range10, 'tree__max_depth':param_range1, \n",
    "               'knn__n_neighbors':param_range1}]\n",
    "\n",
    "gs = GridSearchCV(estimator=eclf, param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "gs = gs.fit(X_train_std, y_train)\n",
    "\n",
    "print('Best accuracy score: %.3f \\nBest parameters: %s' % (gs.best_score_, gs.best_params_))\n",
    "\n",
    "clf = gs.best_estimator_\n",
    "clf.fit(X_train_std, y_train)\n",
    "t1 = time.clock()\n",
    "print('Running time: %.3f' % (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test_std)\n",
    "print('ROC AUC: %.3f \\nAccuracy: %.3f \\nConfusion Matrix:' % (roc_auc_score(y_true=y_test, y_score=y_pred),\n",
    "                                         accuracy_score(y_true=y_test, y_pred=y_pred)))\n",
    "print(confusion_matrix(y_true=y_test, y_pred=y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
