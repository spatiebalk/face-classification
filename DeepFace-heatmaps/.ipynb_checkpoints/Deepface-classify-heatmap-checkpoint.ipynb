{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load weights of DeepFace\n",
    "2. Add classification layer (2)\n",
    "3. For each syn in syn_list calculate the stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from os import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image \n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import keras.initializers\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import cv2\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n",
      "2.2.5\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (152, 152) # set by the model \n",
    "CHANNELS = 3 # RGB image\n",
    "NUM_CLASSES = 8631 # classification layer will be removed \n",
    "LEARN_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "DOWNLOAD_PATH = 'https://github.com/swghosh/DeepFace/releases/download/weights-vggface2-2d-aligned/VGGFace2_DeepFace_weights_val-0.9034.h5.zip'\n",
    "MD5_HASH = '0b21fb70cd6901c96c19ac14c9ea8b89'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_init = keras.initializers.RandomNormal(mean=0, stddev=0.01)\n",
    "bias_init = keras.initializers.Constant(value=0.5)\n",
    "\n",
    "def conv2d_layer(**args):\n",
    "    return keras.layers.Conv2D(**args, \n",
    "        kernel_initializer=wt_init, \n",
    "        bias_initializer=bias_init,\n",
    "        activation=keras.activations.relu)\n",
    "def lc2d_layer(**args):\n",
    "    return keras.layers.LocallyConnected2D(**args, \n",
    "        kernel_initializer=wt_init, \n",
    "        bias_initializer=bias_init,\n",
    "        activation=keras.activations.relu)\n",
    "def dense_layer(**args):\n",
    "    return keras.layers.Dense(**args, \n",
    "        kernel_initializer=wt_init, \n",
    "        bias_initializer=bias_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifying_deepface(image_size=IMAGE_SIZE, channels=CHANNELS, num_classes=NUM_CLASSES, learn_rate=LEARN_RATE, momentum=MOMENTUM):\n",
    "    deepface = keras.models.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(*image_size, channels), name='I0'),\n",
    "        conv2d_layer(filters=32, kernel_size=11, name='C1'),\n",
    "        keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same',  name='M2'),\n",
    "        conv2d_layer(filters=16, kernel_size=9, name='C3'),\n",
    "        lc2d_layer(filters=16, kernel_size=9, name='L4'),\n",
    "        lc2d_layer(filters=16, kernel_size=7, strides=2, name='L5'),\n",
    "        lc2d_layer(filters=16, kernel_size=5, name='L6'),\n",
    "        keras.layers.Flatten(name='F0'),\n",
    "        dense_layer(units=4096, activation=keras.activations.relu, name='F7'),\n",
    "        keras.layers.Dropout(rate=0.5, name='D0'),\n",
    "        dense_layer(units=num_classes, activation=keras.activations.softmax, name='F8')\n",
    "    ], name='DeepFace')\n",
    "    # deepface.summary()\n",
    "\n",
    "    sgd_opt = keras.optimizers.SGD(lr=learn_rate, momentum=momentum)\n",
    "    cce_loss = keras.losses.categorical_crossentropy\n",
    "\n",
    "    deepface.compile(optimizer=sgd_opt, loss=cce_loss, metrics=['accuracy'])\n",
    "    weights = get_weights()\n",
    "    deepface.load_weights(weights)\n",
    "    \n",
    "    return deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights():\n",
    "    filename = 'deepface.zip'\n",
    "    downloaded_file_path = keras.utils.get_file(filename, DOWNLOAD_PATH, \n",
    "        md5_hash=MD5_HASH, extract=True)\n",
    "    downloaded_h5_file = path.join(path.dirname(downloaded_file_path), \n",
    "        path.basename(DOWNLOAD_PATH).rstrip('.zip'))\n",
    "    return downloaded_h5_file\n",
    "\n",
    "\n",
    "def create_deepface():\n",
    "    model = create_classifying_deepface()\n",
    "    weights = get_weights()\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "#     num_classes = 2\n",
    "#     x = model.layers[-2].output\n",
    "#     x = dense_layer(units=num_classes, activation=keras.activations.softmax, name='preds')(x)\n",
    "#     #x = Dense(2, activation='softmax', name='predictions')(x)\n",
    "#     model2 = Model(model.input, x)\n",
    "    \n",
    "#     sgd_opt = keras.optimizers.SGD(lr=LEARN_RATE, momentum=MOMENTUM)\n",
    "#     cce_loss = keras.losses.categorical_crossentropy\n",
    "#     #model2.compile(optimizer=sgd_opt, loss=cce_loss, metrics=['accuracy'])\n",
    " \n",
    "\n",
    "#     model2.compile(\n",
    "#         loss=\"sparse_categorical_crossentropy\",\n",
    "#         optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "#         metrics=[\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "#     #model2.summary()\n",
    "    \n",
    "#     return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(syn, GENERAL_DIR):\n",
    "    \n",
    "    data, labels = [], [] \n",
    "    \n",
    "    syn_dir = GENERAL_DIR + \"\\\\{}\\{}-patients\".format(syn, syn)\n",
    "    ID_dir = GENERAL_DIR + \"\\\\{}\\{}-selected-ID-controls\".format(syn, syn)\n",
    "\n",
    "    # get list of filenames\n",
    "    files_syn = [f for f in listdir(syn_dir) if (isfile(join(syn_dir, f)))and \".jpg\" in f]\n",
    "    files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f))) and \".jpg\" in f]\n",
    "    \n",
    "    print(\"Syn_list: {}, ID_list: {}\".format(len(files_syn), len(files_ID)))\n",
    "\n",
    "    for filename in files_syn:\n",
    "        im = Image.open(join(syn_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        data.append(np.array(im))\n",
    "        labels.append(1)\n",
    "\n",
    "    for filename in files_ID:\n",
    "        im = Image.open(join(ID_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        data.append(np.array(im))\n",
    "        labels.append(0)    \n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(\n",
    "    img_array, model, last_conv_layer_name, classifier_layer_names\n",
    "):\n",
    "    \n",
    "    img_array = tf.convert_to_tensor(img_array, dtype=np.float32)\n",
    "    # First, we create a model that maps the input image to the activations\n",
    "    # of the last conv layer\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # Second, we create a model that maps the activations of the last conv\n",
    "    # layer to the final class predictions\n",
    "    classifier_input = keras.Input(shape=(1, 21, 21, 16))\n",
    "    x = classifier_input\n",
    "    \n",
    "    print(type(x))\n",
    "    print(x.shape)\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    # Then, we compute the gradient of the top predicted class for our input image\n",
    "    # with respect to the activations of the last conv layer\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        # Compute class predictions\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    # This is the gradient of the top predicted class with regard to\n",
    "    # the output feature map of the last conv layer\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient\n",
    "    # over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # We multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" with regard to the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    # The channel-wise mean of the resulting feature map\n",
    "    # is our heatmap of class activation\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "\n",
    "    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "Model: \"DeepFace\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "C1 (Conv2D)                  (None, 142, 142, 32)      11648     \n",
      "_________________________________________________________________\n",
      "M2 (MaxPooling2D)            (None, 71, 71, 32)        0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 63, 63, 16)        41488     \n",
      "_________________________________________________________________\n",
      "L4 (LocallyConnected2D)      (None, 55, 55, 16)        62774800  \n",
      "_________________________________________________________________\n",
      "L5 (LocallyConnected2D)      (None, 25, 25, 16)        7850000   \n",
      "_________________________________________________________________\n",
      "L6 (LocallyConnected2D)      (None, 21, 21, 16)        2829456   \n",
      "_________________________________________________________________\n",
      "F0 (Flatten)                 (None, 7056)              0         \n",
      "_________________________________________________________________\n",
      "F7 (Dense)                   (None, 4096)              28905472  \n",
      "_________________________________________________________________\n",
      "D0 (Dropout)                 (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "F8 (Dense)                   (None, 8631)              35361207  \n",
      "=================================================================\n",
      "Total params: 137,774,071\n",
      "Trainable params: 137,774,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = create_classifying_deepface()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 152, 152, 3)\n",
      "predictions: [[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "img = Image.open(r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\test\\YY1_1.jpg\")\n",
    "img = np.array(img.resize(IMAGE_SIZE))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "print(img.shape)\n",
    "\n",
    "preds = model.predict(img)\n",
    "print(\"predictions: {}\".format(preds))\n",
    "\n",
    "last_conv_layer_name = \"L6\"\n",
    "classifier_layer_names = [\"F0\", \"F7\", \"D0\", \"F8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "(?, 1, 21, 21, 16)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead. If you need this feature, please file a feature request at https://github.com/tensorflow/tensorflow/issues/new",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-7ff17cbeefd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mheatmap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_gradcam_heatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_conv_layer_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifier_layer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-6e08b6e8d7e8>\u001b[0m in \u001b[0;36mmake_gradcam_heatmap\u001b[1;34m(img_array, model, last_conv_layer_name, classifier_layer_names)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# This is the gradient of the top predicted class with regard to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# the output feature map of the last conv layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_class_channel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_conv_layer_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# This is a vector where each entry is the mean intensity of the gradient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1013\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1015\u001b[1;33m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[0;32m   1016\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\eager\\imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     74\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[1;32mC:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_grad.py\u001b[0m in \u001b[0;36m_SwitchGrad\u001b[1;34m(op, *grad)\u001b[0m\n\u001b[0;32m     42\u001b[0m   \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m   \u001b[0mop_ctxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m   \u001b[0mgrad_ctxt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_control_flow_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\MyPrograms\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36m_get_control_flow_context\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_control_flow_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     raise NotImplementedError(\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[1;34m\"tf.GradientTape.gradients() does not support graph control flow \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"operations like tf.cond or tf.while at this time. Use tf.gradients() \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[1;34m\"instead. If you need this feature, please file a feature request at \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead. If you need this feature, please file a feature request at https://github.com/tensorflow/tensorflow/issues/new"
     ]
    }
   ],
   "source": [
    "heatmap = make_gradcam_heatmap(img, model, last_conv_layer_name, classifier_layer_names)\n",
    "\n",
    "plt.matshow(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__) ## 2.2.0\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "model  = create_deepface()\n",
    "\n",
    "im = Image.open(r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\test\\YY1_1.jpg\")\n",
    "im = np.array(im.resize(IMAGE_SIZE))\n",
    "\n",
    "#im = preprocessing.image.img_to_array(im)\n",
    "im = np.expand_dims(im, axis=0)\n",
    "\n",
    "im = tf.convert_to_tensor(im, dtype=np.float32)\n",
    "\n",
    "conv_layer = model.get_layer(\"L6\")\n",
    "heatmap_model = Model([model.input], [conv_layer.output, model.output])\n",
    "\n",
    "with tf.GradientTape() as gtape:\n",
    "    conv_output, predictions = heatmap_model(im)\n",
    "    i = tf.math.argmax(predictions[0], -1) #  .eval(session=tf.InteractiveSession()) #.numpy()\n",
    "    \n",
    "    loss = predictions[:, i] #np.argmax(predictions[0])]\n",
    "    print(loss)\n",
    "    print(type(loss))\n",
    "    gtape.watch(conv_output)\n",
    "    gtape.watch(loss)\n",
    "grads = gtape.gradient(loss, conv_output)\n",
    "pooled_grads = K.mean(grads, axis=(0,1,2))\n",
    "\n",
    "heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "max_heat = np.max(heatmap)\n",
    "if max_heat == 0:\n",
    "    max_heat = 1e-10\n",
    "heatmap /= max_heat\n",
    "\n",
    "print(heatmap.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "BATCH_SIZE = 32\n",
    "GENERAL_DIR = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\" \n",
    "\n",
    "# load img data\n",
    "syn_list = ['ADNP', 'ANKRD11', 'CDK13', 'DEAF1', 'DYRK1A', 'EHMT1', 'FBXO11', 'SON', 'WAC', 'YY1', 'KDVS']\n",
    "results_file = open(\"results/deepface_classification.txt\", \"w\")\n",
    "\n",
    "for syn in ['YY1']:\n",
    "    data, labels = load_data(syn, GENERAL_DIR)\n",
    "\n",
    "    results_file.write(\"Syndrome {} with {} patients and {} controls\\n\".format(syn, labels.tolist().count(1), labels.tolist().count(0)))\n",
    "    all_y, all_probs, all_preds = [], [], [] \n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    for train_index, test_index in tqdm(loo.split(data)):\n",
    "        X_train, X_test = np.array(data[train_index]), data[test_index]\n",
    "        y_train, y_test = np.array(labels[train_index]), labels[test_index]\n",
    "        \n",
    "        %reset_selective \"model\"\n",
    "        \n",
    "        model = create_deepface()\n",
    "        model.fit(x=X_train, y=y_train, batch_size=BATCH_SIZE, epochs=1, shuffle=True)\n",
    "\n",
    "        y_pred_array = model.predict(X_test)\n",
    "        y_pred = tf.math.argmax(y_pred_array, -1).numpy()\n",
    "\n",
    "        all_y.append(y_test[0])\n",
    "        all_probs.append(y_pred_array[0][1])\n",
    "        all_preds.append(y_pred)  \n",
    "        \n",
    "        \n",
    "        \n",
    "    aroc = roc_auc_score(all_y, all_probs, labels=[0,1])\n",
    "    tn, fp, fn, tp = confusion_matrix(all_y, all_preds, labels=[0,1]).ravel()\n",
    "    spec = tn / (tn+fp)  \n",
    "    sens = tp / (tp+fn)\n",
    "\n",
    "    results_file.write(\"AROC: {:.4f}, spec: {:.4f}, sens: {:.4f}\\n\\n\".format(aroc, spec, sens))\n",
    "    \n",
    "    break\n",
    "    \n",
    "results_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def deepface_reps(GENERAL_DIR, syn_name):\n",
    "\n",
    "    model = create_deepface()\n",
    "    syn_rep, ID_rep = [], []\n",
    "\n",
    "    syn_dir = GENERAL_DIR + \"\\\\{}\\{}-patients\".format(syn_name, syn_name)\n",
    "    ID_dir = GENERAL_DIR + \"\\\\{}\\{}-selected-ID-controls\".format(syn_name, syn_name)\n",
    "\n",
    "    # get list of filenames\n",
    "    files_syn = [f for f in listdir(syn_dir) if (isfile(join(syn_dir, f)))and syn_name in f]\n",
    "    files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f))) and \".jpg\" in f]\n",
    "    \n",
    "    print(\"Syn_list: {}, ID_list: {}\".format(len(files_syn), len(files_ID)))\n",
    "\n",
    "        \n",
    "    # for each kdv image save deepface rep as list:\n",
    "    for filename in files_syn:\n",
    "        im = Image.open(join(syn_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        output = model.predict(np.expand_dims(im, axis=0))\n",
    "        syn_rep.append([filename] + output[0].tolist())  \n",
    "\n",
    "\n",
    "    # for each ID image save deepface rep as list:\n",
    "    for filename in files_ID:\n",
    "        im = Image.open(join(ID_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        output = model.predict(np.expand_dims(im, axis=0))\n",
    "        ID_rep.append([filename] + output[0].tolist())\n",
    "\n",
    "    print(\"Syn_reps: {}, ID_reps: {}\".format(len(syn_rep), len(ID_rep)))\n",
    "\n",
    "    # location to save representation\n",
    "    csv_file_syn = GENERAL_DIR + \"\\\\{}\\\\representations\\\\{}-patients-deepface.csv\".format(syn_name, syn_name)\n",
    "    csv_file_ID = GENERAL_DIR + \"\\\\{}\\\\representations\\\\ID-controls-deepface.csv\".format(syn_name)\n",
    "    \n",
    "    # save representation of kdv patients\n",
    "    with open(csv_file_syn, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(syn_rep)\n",
    "\n",
    "    # save representation of ID controls\n",
    "    with open(csv_file_ID, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(ID_rep)\n",
    "\n",
    "    print(\"Done with saving all deepface representations for {}.\".format(syn_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
