{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save facereader (landmark) representations in one main csv\n",
    "This notebook saves the representation for all available patient and control images for the landmarks of facereader and for the distances between the landmarks for the left and right side combined. This notebook has to be run before the complete_pipeline.ipynb can be run, as this precomputes all the features for the facereader representations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import csv\n",
    "import itertools\n",
    "from scipy.spatial import distance\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERAL_DIR = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\"\n",
    "syn_list = ['22q11','ADNP', 'ANKRD11','CDK13', 'DEAF1', 'DYRK1A', 'EHMT1', 'FBXO11', 'KDVS', 'SON', 'WAC', 'YY1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save landmarks  for all syndromes and controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_landmarks_syn(GENERAL_DIR, out_file):\n",
    "    syn_rep = []\n",
    "\n",
    "    # for each syndrome\n",
    "    for syn in syn_list:\n",
    "        syn_dir = GENERAL_DIR + \"\\\\{}\\\\{}-all-photos\".format(syn, syn)\n",
    "\n",
    "        # get list of filenames\n",
    "        files_syn = [f for f in listdir(syn_dir) if (isfile(join(syn_dir, f)) and \".jpg\" in f)]\n",
    "\n",
    "        # for every image of this syndrome\n",
    "        for filename in files_syn: \n",
    "\n",
    "            # open file\n",
    "            FR.GrabCredits(1)        \n",
    "            bitmap = Drawing.Bitmap(join(syn_dir, filename))\n",
    "            try:\n",
    "                result = (FR.AnalyzeFace(bitmap))\n",
    "                result = json.loads(result.ToJson())\n",
    "            except:\n",
    "                print(\"An exception occurred\")\n",
    "                result = 'error'\n",
    "                syn_rep.append([filename] + np.zeros(510*3).tolist())\n",
    "\n",
    "            if isinstance(result, Mapping):\n",
    "                if result['FaceAnalyzed']:\n",
    "                    landmarks = []\n",
    "                    landmarks_dict = result['Landmarks3D']\n",
    "                    for item in landmarks_dict:\n",
    "                        landmarks.append(item['X'])\n",
    "                        landmarks.append(item['Y'])\n",
    "                        landmarks.append(item['Z'])\n",
    "    \n",
    "                    syn_rep.append([filename] + landmarks)  \n",
    "                else:\n",
    "                    syn_rep.append([filename] + np.zeros(510*3).tolist())\n",
    "\n",
    "    # save representation of patients\n",
    "    with open(outfile, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(syn_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_landmarks_ID(GENERAL_DIR, out_file):\n",
    "    ID_rep = []\n",
    "    ID_dir = GENERAL_DIR + \"\\\\ID-controls\"\n",
    "\n",
    "    # get list of filenames\n",
    "    files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f)) and \".jpg\" in f)]\n",
    "\n",
    "    # for every image of this syndrome\n",
    "    for filename in files_ID: \n",
    "    \n",
    "        # open file\n",
    "        FR.GrabCredits(1)        \n",
    "        bitmap = Drawing.Bitmap(join(ID_dir, filename))\n",
    "        try:\n",
    "            result = (FR.AnalyzeFace(bitmap))\n",
    "            result = json.loads(result.ToJson())\n",
    "        except:\n",
    "            print(\"An exception occurred\")\n",
    "            result = 'error'\n",
    "            ID_rep.append([filename] + np.zeros(510*3).tolist())\n",
    "\n",
    "        if isinstance(result, Mapping):\n",
    "            if result['FaceAnalyzed']:\n",
    "                landmarks = []\n",
    "                landmarks_dict = result['Landmarks3D']\n",
    "                for item in landmarks_dict:\n",
    "                    landmarks.append(item['X'])\n",
    "                    landmarks.append(item['Y'])\n",
    "                    landmarks.append(item['Z'])\n",
    "\n",
    "                ID_rep.append([filename] + landmarks)  \n",
    "            else:\n",
    "                ID_rep.append([filename] + np.zeros(510*3).tolist())\n",
    "\n",
    "    # save representation of control images\n",
    "    with open(out_file, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(ID_rep)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outfile_syn = GENERAL_DIR + \"\\\\features_facereader_patient_groups.csv\"\n",
    "# save_all_landmarks_syn(GENERAL_DIR, out_file_syn)\n",
    "\n",
    "# out_file_ID = GENERAL_DIR + \"\\\\features_facereader_all_controls.csv\"\n",
    "# save_all_landmarks_ID(GENERAL_DIR, out_file_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Save landmark distances for all syndromes and controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT = [0, 1, 2, 3, 4, 5, 6, 7, 8, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341]\n",
    "RIGHT = [9, 10, 11, 12, 13, 14, 15, 16, 17, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 157, 158, 168, 173, 174, 190, 191, 205, 210, 213, 217, 262, 263, 269, 278, 281, 282, 284, 288, 292, 294, 295, 296, 297, 298, 299, 302, 304, 305, 306, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(keypoints):\n",
    "    feats  = []\n",
    "    combs = [comb for comb in itertools.combinations([*range(0, len(keypoints))], 2)]\n",
    "    for comb in combs:\n",
    "        a = comb[0]\n",
    "        b = comb[1]\n",
    "        feats.append(distance.euclidean(keypoints[a], keypoints[b]))\n",
    "    \n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_all_landmark_dis_reps(GENERAL_DIR, in_file, out_file):\n",
    "    rep = []\n",
    "    with open(in_file, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            landmarks_left, landmarks_right = [], []\n",
    "            i = 1\n",
    "            count = 0\n",
    "            while i < len(row[1:]):\n",
    "                if count in LEFT:\n",
    "                    landmarks_left.append((float(row[i]), float(row[i+1]), float(row[i+2])))\n",
    "                if count in RIGHT:\n",
    "                    landmarks_right.append((float(row[i]), float(row[i+1]), float(row[i+2])))       \n",
    "                count += 1\n",
    "                i+=3    \n",
    "\n",
    "            feats_left = get_distances(landmarks_left)\n",
    "            feats_right = get_distances(landmarks_right)\n",
    "            all_feats = feats_left + feats_right\n",
    "\n",
    "            assert len(all_feats) == len(feats_left) + len(feats_right)\n",
    "            rep.append([row[0]] + all_feats)\n",
    "\n",
    "    with open(out_file, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save landmark distances for syndrome images\n",
    "in_file_syn = GENERAL_DIR+ \"\\\\features_facereader_landmarks_patient_groups.csv\"\n",
    "out_file_syn = GENERAL_DIR+ \"\\\\features_facereader_landmarks_distances_patient_groups_left_right.csv\"\n",
    "save_all_landmark_dis_reps(GENERAL_DIR, in_file_syn, out_file_syn)\n",
    "\n",
    "# # save landmark distances for control images\n",
    "# in_file_ID = GENERAL_DIR+ \"\\\\features_facereader_landmarks_all_controls.csv\"\n",
    "# out_file_ID = GENERAL_DIR+ \"\\\\features_facereader_landmarks_distances_all_controls_left_right.csv\"\n",
    "# save_all_landmark_dis_reps(GENERAL_DIR, in_file_ID, out_file_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
