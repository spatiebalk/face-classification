{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "import numpy as np #1.16.4 otherwise futurewarning tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 11\n",
    "BATCH_SIZE = 8\n",
    "NUM_POINTS = 510"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    GENERAL_DIR = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\" \n",
    "    syn_list = ['ADNP', 'ANKRD11', 'CDK13', 'DEAF1', 'DYRK1A', 'EHMT1', 'FBXO11', 'SON', 'WAC', 'YY1', 'KDVS']\n",
    "    file = GENERAL_DIR+ \"\\\\features_facereader_landmarks_patient_groups.csv\"\n",
    "    class_map = {}\n",
    "    \n",
    "    for index, syn in enumerate(syn_list):\n",
    "        class_map[index] = syn\n",
    "        \n",
    "        files = [f for f in listdir(GENERAL_DIR +\"\\\\{}\\\\{}-all-photos\".format(syn, syn)) if \"jpg\" in f]\n",
    "\n",
    "        with open(file, newline='') as csvfile:\n",
    "            reader = csv.reader(csvfile, delimiter=',')\n",
    "            for row in reader:\n",
    "                if row[0] in files:\n",
    "                    fr_rep = [float(f) for f in row[1:]]\n",
    "                    if not all(v == 0 for v in fr_rep):\n",
    "\n",
    "                        rep = []\n",
    "                        i = 1\n",
    "                        while i < len(row[1:]):\n",
    "                            rep.append([float(row[i]), float(row[i+1]), float(row[i+2])])\n",
    "                            i+=3  \n",
    "                        data.append(rep)\n",
    "                        labels.append(index)\n",
    "                        \n",
    "    \n",
    "    return np.array(data), np.array(labels), class_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(points, label):\n",
    "    points += tf.random.uniform(points.shape, -0.005, 0.005, dtype=tf.float64)\n",
    "    points = tf.random.shuffle(points)\n",
    "    return points, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 510, 3)\n",
      "(221,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAOBUlEQVR4nO3db4hl9X3H8fenrmI0FXfr7LL1TyeBxUQENR2sqRDabCymirtPDAoJQxD2SZpqCYRNnpQ+20IJyYMSWNRkINbGGmUXLTbLJBIKwWb800azyqZ2o1snOxMTq0mg1uTbB3OMm9lZ752Z+8ffzvsFy7nnN/fO+V5W3549e8+YqkKS1J7fGfcAkqS1MeCS1CgDLkmNMuCS1CgDLkmN2jTKg11wwQU1OTk5ykNKUvMef/zxn1TVxPL1kQZ8cnKSubm5UR5SkpqX5EcrrXsJRZIaZcAlqVEGXJIa1TPgSS5N8tQJv15NckeSLUkOJTnSbTePYmBJ0pKeAa+q56rqyqq6EvhD4JfAg8BeYLaqdgCz3b4kaURWewllJ/CfVfUjYBcw063PALsHOZgk6e2tNuC3APd2j7dV1TxAt9260guS7Ekyl2RucXFx7ZNKkn5L3wFPchZwE/BPqzlAVe2vqqmqmpqYOOlz6JKkNVrNGfhHgSeq6ni3fzzJdoBuuzDo4SRJp7aaOzFv5a3LJwAHgWlgX7c9MMC5JGngJvc+PLZjH913w8C/Z19n4EnOAa4DHjhheR9wXZIj3df2DXw6SdIp9XUGXlW/BH5v2drLLH0qRZI0Bt6JKUmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmN6ivgSc5Pcn+SZ5McTvLBJFuSHEpypNtuHvawkqS39HsG/iXgkap6H3AFcBjYC8xW1Q5gttuXJI1Iz4AnOQ/4EHAXQFW9XlWvALuAme5pM8DuYQ0pSTpZP2fg7wUWga8keTLJnUnOBbZV1TxAt9260ouT7Ekyl2RucXFxYINL0kbXT8A3AR8AvlxVVwG/YBWXS6pqf1VNVdXUxMTEGseUJC3XT8CPAceq6rFu/36Wgn48yXaAbrswnBElSSvpGfCq+jHwYpJLu6WdwA+Ag8B0tzYNHBjKhJKkFW3q83mfBu5JchbwPPBJluJ/X5LbgBeAm4czoiRpJX0FvKqeAqZW+NLOwY4jSeqXd2JKUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqMMuCQ1yoBLUqP6+r/SJzkKvAb8CnijqqaSbAG+DkwCR4GPVdXPhjOmJGm51ZyB/2lVXVlVU93+XmC2qnYAs92+JGlE1nMJZRcw0z2eAXavfxxJUr/6DXgB30zyeJI93dq2qpoH6LZbV3phkj1J5pLMLS4urn9iSRLQ5zVw4NqqeinJVuBQkmf7PUBV7Qf2A0xNTdUaZpQkraCvM/CqeqnbLgAPAlcDx5NsB+i2C8MaUpJ0sp4BT3Jukt998zHwZ8DTwEFgunvaNHBgWENKkk7WzyWUbcCDSd58/j9U1SNJvgfcl+Q24AXg5uGNKUlarmfAq+p54IoV1l8Gdg5jKElSb96JKUmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmNMuCS1CgDLkmN6jvgSc5I8mSSh7r9LUkOJTnSbTcPb0xJ0nKrOQO/HTh8wv5eYLaqdgCz3b4kaUT6CniSi4AbgDtPWN4FzHSPZ4Ddgx1NkvR2+j0D/yLwWeDXJ6xtq6p5gG67daUXJtmTZC7J3OLi4rqGlSS9pWfAk9wILFTV42s5QFXtr6qpqpqamJhYy7eQJK1gUx/PuRa4KcmfA2cD5yX5GnA8yfaqmk+yHVgY5qCSpN/W8wy8qj5XVRdV1SRwC/Ctqvo4cBCY7p42DRwY2pSSpJOs53Pg+4DrkhwBruv2JUkj0s8llN+oqkeBR7vHLwM7Bz+SJKkfqwr4RjW59+GxHPfovhvGclxJbfBWeklqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEYZcElqlAGXpEb1DHiSs5P8W5J/T/JMkr/p1rckOZTkSLfdPPxxJUlv6ucM/H+BD1fVFcCVwPVJrgH2ArNVtQOY7fYlSSPSM+C15Ofd7pndrwJ2ATPd+gyweygTSpJW1Nc18CRnJHkKWAAOVdVjwLaqmgfotltP8do9SeaSzC0uLg5qbkna8PoKeFX9qqquBC4Crk5yeb8HqKr9VTVVVVMTExNrnVOStMyqPoVSVa8AjwLXA8eTbAfotgsDn06SdEr9fAplIsn53eN3AR8BngUOAtPd06aBA8MaUpJ0sk19PGc7MJPkDJaCf19VPZTku8B9SW4DXgBuHuKckqRlega8qv4DuGqF9ZeBncMYSpLUm3diSlKjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjDLgkNcqAS1KjegY8ycVJvp3kcJJnktzerW9JcijJkW67efjjSpLe1M8Z+BvAZ6rq/cA1wKeSXAbsBWaragcw2+1LkkakZ8Crar6qnugevwYcBi4EdgEz3dNmgN3DGlKSdLJVXQNPMglcBTwGbKuqeViKPLD1FK/Zk2Quydzi4uL6ppUk/UbfAU/ybuAbwB1V9Wq/r6uq/VU1VVVTExMTa5lRkrSCvgKe5EyW4n1PVT3QLR9Psr37+nZgYTgjSpJWsqnXE5IEuAs4XFVfOOFLB4FpYF+3PTCUCTewyb0Pj+W4R/fdMJbjSlqdngEHrgU+AXw/yVPd2udZCvd9SW4DXgBuHs6IkqSV9Ax4Vf0rkFN8eedgx5Ek9cs7MSWpUQZckhplwCWpUf38JaZ02hvXJ37AT/1o7TwDl6RGGXBJapSXUHQSLyeMljdsaa08A5ekRhlwSWpUM5dQxvnHekl6J/IMXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIa1fNnoSS5G7gRWKiqy7u1LcDXgUngKPCxqvrZ8MaUNGj+2OD29XMG/lXg+mVre4HZqtoBzHb7kqQR6hnwqvoO8NNly7uAme7xDLB7wHNJknpY64+T3VZV8wBVNZ9k66memGQPsAfgkksuWePhtFH4Y4M3Bn+fB2Pof4lZVfuraqqqpiYmJoZ9OEnaMNYa8ONJtgN024XBjSRJ6sdaA34QmO4eTwMHBjOOJKlfPQOe5F7gu8ClSY4luQ3YB1yX5AhwXbcvSRqhnn+JWVW3nuJLOwc8iyRpFbwTU5IaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIaZcAlqVEGXJIata6AJ7k+yXNJfphk76CGkiT1tuaAJzkD+Hvgo8BlwK1JLhvUYJKkt7eeM/CrgR9W1fNV9Trwj8CuwYwlSepl0zpeeyHw4gn7x4A/Wv6kJHuAPd3uz5M8t8bjXQD8ZI2vbZXveWPwPW8A+dt1vec/WGlxPQHPCmt10kLVfmD/Oo6zdLBkrqqm1vt9WuJ73hh8zxvDMN7zei6hHAMuPmH/IuCl9Y0jSerXegL+PWBHkvckOQu4BTg4mLEkSb2s+RJKVb2R5C+AfwHOAO6uqmcGNtnJ1n0ZpkG+543B97wxDPw9p+qky9aSpAZ4J6YkNcqAS1Kjmgj4RrtlP8nFSb6d5HCSZ5LcPu6ZRiHJGUmeTPLQuGcZhSTnJ7k/ybPd7/UHxz3TsCX5q+6f6aeT3Jvk7HHPNGhJ7k6ykOTpE9a2JDmU5Ei33TyIY73jA75Bb9l/A/hMVb0fuAb41AZ4zwC3A4fHPcQIfQl4pKreB1zBaf7ek1wI/CUwVVWXs/Thh1vGO9VQfBW4ftnaXmC2qnYAs93+ur3jA84GvGW/quar6onu8Wss/Yt94XinGq4kFwE3AHeOe5ZRSHIe8CHgLoCqer2qXhnvVCOxCXhXkk3AOZyG945U1XeAny5b3gXMdI9ngN2DOFYLAV/plv3TOmYnSjIJXAU8Nt5Jhu6LwGeBX497kBF5L7AIfKW7bHRnknPHPdQwVdV/A38HvADMA/9TVd8c71Qjs62q5mHpBA3YOohv2kLA+7pl/3SU5N3AN4A7qurVcc8zLEluBBaq6vFxzzJCm4APAF+uqquAXzCgP1a/U3XXfXcB7wF+Hzg3ycfHO1XbWgj4hrxlP8mZLMX7nqp6YNzzDNm1wE1JjrJ0iezDSb423pGG7hhwrKre/JPV/SwF/XT2EeC/qmqxqv4PeAD44zHPNCrHk2wH6LYLg/imLQR8w92ynyQsXRs9XFVfGPc8w1ZVn6uqi6pqkqXf329V1Wl9ZlZVPwZeTHJpt7QT+MEYRxqFF4BrkpzT/TO+k9P8L25PcBCY7h5PAwcG8U3X89MIR2IMt+y/E1wLfAL4fpKnurXPV9U/j3EmDd6ngXu6E5PngU+OeZ6hqqrHktwPPMHSJ62e5DS8pT7JvcCfABckOQb8NbAPuC/JbSz9h+zmgRzLW+klqU0tXEKRJK3AgEtSowy4JDXKgEtSowy4JDXKgEtSowy4JDXq/wETJn7r83LKGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data, labels, class_map = load_data()\n",
    "\n",
    "print(data.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "plt.hist(labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn(x, filters):\n",
    "    x = layers.Conv1D(filters, kernel_size=1, padding='valid')(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)\n",
    "\n",
    "def dense_bn(x, filters):\n",
    "    x = layers.Dense(filters)(x)\n",
    "    x = layers.BatchNormalization(momentum=0.0)(x)\n",
    "    return layers.Activation(\"relu\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrthogonalRegularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, num_features, l2reg=0.001):\n",
    "        self.num_features = num_features\n",
    "        self.l2reg = l2reg\n",
    "        self.eye = tf.eye(num_features)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        x = tf.reshape(x, (-1, self.num_features, self.num_features))\n",
    "        xxt = tf.tensordot(x, x, axes=(2,2))\n",
    "        xxt = tf.reshape(xxt, (-1, self.num_features, self.num_features))\n",
    "        return tf.reduce_sum(self.l2reg * tf.square(xxt - self.eye))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tnet(inputs, num_features):\n",
    "    bias = keras.initializers.Constant(np.eye(num_features).flatten())\n",
    "    reg = OrthogonalRegularizer(num_features)\n",
    "    \n",
    "    x = conv_bn(inputs, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dense(\n",
    "        num_features * num_features, \n",
    "        kernel_initializer=\"zeros\",\n",
    "        bias_initializer=bias,\n",
    "        activity_regularizer=reg)(x)\n",
    "    \n",
    "    feat_T = layers.Reshape((num_features, num_features))(x)\n",
    "    \n",
    "    return layers.Dot(axes=(2,1))([inputs, feat_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "\n",
    "def generate_model():\n",
    "\n",
    "    inputs = keras.Input(shape=(NUM_POINTS, 3))\n",
    "\n",
    "    x = tnet(inputs, 3)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = tnet(x, 32)\n",
    "    x = conv_bn(x, 32)\n",
    "    x = conv_bn(x, 64)\n",
    "    x = conv_bn(x, 512)\n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    x = dense_bn(x, 256)\n",
    "    x = layers.Dropout(rate=0.3)(x)\n",
    "    x = dense_bn(x, 128)\n",
    "    x = layers.Dropout(rate=0.3)(x)\n",
    "\n",
    "    outputs = layers.Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"pointnet\")\n",
    "    #model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "        metrics=[\"sparse_categorical_accuracy\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "    metrics=[\"sparse_categorical_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def gradCAM(model, X_test, y_test, intensity=0.5, res=250):\n",
    "    \n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.gca(projection='3d')\n",
    "#     print\n",
    "#     ax.plot(X_test[0][:][0], X_test[0][:][1], X_test[0][:][2])\n",
    "#     ax.legend()\n",
    "#     plt.show()\n",
    "\n",
    "    y_pred_array = model.predict(X_test)\n",
    "    y_pred = tf.math.argmax(y_pred_array, -1).eval(session=tf.Session())\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer = model.layers[-13]\n",
    "        iterate = tf.keras.Model([model.inputs], [model.output, last_conv_layer.output])\n",
    "        model_out, last_conv_layer = iterate(X_test)\n",
    "        class_out = model_out[:, np.argmax(model_out[0])]\n",
    "        grads = tape.gradient(class_out, last_conv_layer)\n",
    "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "        \n",
    "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0)\n",
    "    heatmap /= np.max(heatmap)\n",
    "    heatmap = heatmap.reshape((8,8))\n",
    "    \n",
    "    cv2.imshow(cv2.resize(heatmap, (res, res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 510, 3)\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:04, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-9ebeda41111a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0my_pred_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "predictions_probs = []\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "i = 0\n",
    "for train_index, test_index in tqdm(loo.split(data)):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    model = generate_model()\n",
    "       \n",
    "    print(X_train.shape)\n",
    "    print(type(X_train))\n",
    "    print(type(X_train[0]))\n",
    "    print(type(X_train[0][0]))\n",
    "\n",
    "    model.fit(x=X_train, y=y_train, batch_size=BATCH_SIZE, epochs=10, shuffle=True)\n",
    "    \n",
    "    y_pred_array = model.predict(X_test)\n",
    "    y_pred = tf.math.argmax(y_pred_array, -1).numpy()\n",
    "    \n",
    "    predictions.append([y_test[0], y_pred[0]])\n",
    "    predictions_probs.append([y_test[0], y_pred_array[0]])\n",
    "        \n",
    "    i+=1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "confusion_matrix = np.zeros((11, 11))\n",
    "\n",
    "\n",
    "for [true, pred] in predictions:\n",
    "    confusion_matrix[pred][true] += 1\n",
    "    \n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(confusion_matrix)\n",
    "plt.xlabel(\"True value\")\n",
    "plt.ylabel(\"Predicted value\")\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_true, y_probs = [], []\n",
    "\n",
    "for [true, pred] in predictions_probs:\n",
    "    y_true.append(true)\n",
    "    y_probs.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_true)\n",
    "print(y_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macro_roc_auc_ovo = roc_auc_score(y_true, y_probs, multi_class=\"ovo\", average=\"macro\", labels=[0,1,2,3,4,5,6,7,8,9,10])\n",
    "weighted_roc_auc_ovo = roc_auc_score(y_true, y_probs, multi_class=\"ovo\", average=\"weighted\", labels=[0,1,2,3,4,5,6,7,8,9,10])\n",
    "macro_roc_auc_ovr = roc_auc_score(y_true, y_probs, multi_class=\"ovr\", average=\"macro\", labels=[0,1,2,3,4,5,6,7,8,9,10])\n",
    "weighted_roc_auc_ovr = roc_auc_score(y_true, y_probs, multi_class=\"ovr\", average=\"weighted\", labels=[0,1,2,3,4,5,6,7,8,9,10])\n",
    "\n",
    "print(\"One-vs-One ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovo, weighted_roc_auc_ovo))\n",
    "\n",
    "print(\"One-vs-Rest ROC AUC scores:\\n{:.6f} (macro),\\n{:.6f} \"\n",
    "      \"(weighted by prevalence)\"\n",
    "      .format(macro_roc_auc_ovr, weighted_roc_auc_ovr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
