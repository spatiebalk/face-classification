{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## conda install -c conda-forge dlib\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import dlib\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "    # take a bounding predicted by dlib and convert it\n",
    "    # to the format (x, y, w, h) as we would normally do\n",
    "    # with OpenCV\n",
    "    \n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    \n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    \n",
    "    # loop over the 68 facial landmarks and convert them\n",
    "    # to a 2-tuple of (x, y)-coordinates\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 2.0, 3.0, 4.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "listt = [2, 4, 6, 8, 10]\n",
    "newList = [x / 2 for x in listt]\n",
    "print(newList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(image, keypoints): ## all possible combinations instead of 11 \n",
    "    assert keypoints.shape == (68,2)\n",
    "    feats = []\n",
    "    denom = np.linalg.norm(keypoints[0]-keypoints[16])\n",
    "    \n",
    "    combs = [comb for comb in itertools.combinations([*range(0, len(keypoints)-1)], 2)]\n",
    "    for comb in combs:\n",
    "        a = comb[0]\n",
    "        b = comb[1]\n",
    "        \n",
    "        if not (a ==0 and b == 16):\n",
    "            feats.append(np.linalg.norm(keypoints[a]-keypoints[b])/denom)\n",
    "    \n",
    "    px_size = 20\n",
    "    text_feats = texture_feature(image, keypoints, px_size)    \n",
    "    text_feats = [x / 255 for x in text_feats]\n",
    "\n",
    "    return [], feats+text_feats\n",
    "\n",
    "def texture_feature(image, keypoints, px_size):\n",
    "    \n",
    "    indices = [36, 39, 42, 45, 31, 33, 35, 48, 54]\n",
    "    features = []\n",
    "\n",
    "    for i in indices:\n",
    "        keypoint = keypoints[i]\n",
    "        (x, y) = keypoint\n",
    "        small_image = image[y-px_size:y+px_size+1, x-px_size:x+px_size+1]\n",
    "\n",
    "        median = cv2.medianBlur(small_image, 5)\n",
    "        resized = cv2.resize(median, (10,10), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "        features.append(resized)\n",
    "\n",
    "    return np.array(features).flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(path):\n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "\n",
    "    image = cv2.imread(path)\n",
    "    image = imutils.resize(image, width=500)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(image, 1)\n",
    "    for (i, rect) in enumerate(rects):\n",
    "        \n",
    "        shape = predictor(image, rect)\n",
    "        shape = shape_to_np(shape)\n",
    "\n",
    "        keypoints, feats = extract_features(image, shape)\n",
    "    \n",
    "        return feats\n",
    "    print(\"No face found\")\n",
    "    print(path)\n",
    "    return np.zeros(11).tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for (i, rect) in enumerate(rects):\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = shape_to_np(shape)\n",
    "    \n",
    "    keypoints, feats = extract_features(shape)\n",
    "    \n",
    "    (x, y, w, h) = rect_to_bb(rect)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2\n",
    "    # cv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "        #cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    for (x, y) in keypoints:\n",
    "        cv2.circle(image, (x, y), 1, (0, 0, 255), -1)\n",
    "\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving all images with this representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "path_to_shape_predictor = \"models/shape_predictor_68_face_landmarks.dat\"\n",
    "predictor = dlib.shape_predictor(path_to_shape_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_age = 1\n",
    "highest_age = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# open directories\n",
    "kdv_dir = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\kdv\\kdv-patients-age-group-\"+str(lowest_age) + \"-\" + str(highest_age)\n",
    "ID_dir = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\kdv\\kdv-selected-ID-controls-age-group-\"+str(lowest_age) + \"-\" + str(highest_age)\n",
    "\n",
    "# get list of filenames\n",
    "files_kdv = [f for f in listdir(kdv_dir) if (isfile(join(kdv_dir, f)) & (\"crop_sized.jpg\" in f))]\n",
    "files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f)) & (\"crop_sized.JPG\" in f))]\n",
    "\n",
    "print(len(files_kdv))\n",
    "print(len(files_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "3110\n"
     ]
    }
   ],
   "source": [
    "kdv_rep = []\n",
    "\n",
    "import time\n",
    "\n",
    "# for each kdv image save deepface rep as list:\n",
    "for filename in files_kdv:\n",
    "#     start = time.time()\n",
    "    feats = get_features(join(kdv_dir, filename))\n",
    "    kdv_rep.append([filename] + feats) \n",
    "#     end = time.time()\n",
    "#     print(\"Time to get deepface representation: {:.4f}\".format(end - start))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No face found\n",
      "H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\kdv-patients-age-group-17-40\\kdvs_52_crop_sized.jpg\n",
      "Done with saving all dlib representations.\n"
     ]
    }
   ],
   "source": [
    "ID_rep = []\n",
    "\n",
    "# for each ID image save deepface rep as list:\n",
    "for filename in files_ID:\n",
    "    feats = get_features(join(ID_dir, filename))\n",
    "    ID_rep.append([filename] + feats)  \n",
    "\n",
    "# location to save representation\n",
    "csv_file_kdv = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\representations\\kdv-patients-dlib-cropped-age-group-\"+str(lowest_age) + \"-\" + str(highest_age)+\".csv\"\n",
    "csv_file_ID = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\representations\\ID-controls-dlib-cropped-age-group-\"+str(lowest_age) + \"-\" + str(highest_age)+\".csv\"\n",
    "\n",
    "# save representation of kdv patients\n",
    "with open(csv_file_kdv, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(kdv_rep)\n",
    "\n",
    "# save representation of ID controls\n",
    "with open(csv_file_ID, \"w\", newline=\"\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(ID_rep)\n",
    "\n",
    "print(\"Done with saving all dlib representations.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
