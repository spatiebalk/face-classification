{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from os import path, listdir\n",
    "from os.path import isfile, join\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import cv2\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "GENERAL_DIR = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\" \n",
    "syn_list =  ['ADNP', 'ANKRD11', 'CDK13', 'DEAF1', 'DYRK1A', 'EHMT1', 'FBXO11','KDVS', 'SON', 'WAC', 'YY1']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(tf.__version__) # 2.0.0\n",
    "print(keras.__version__) # 2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (152, 152) # set by the model\n",
    "CHANNELS = 3 # RGB image\n",
    "NUM_CLASSES = 8631 # classification layer will be removed\n",
    "LEARN_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "DOWNLOAD_PATH = 'https://github.com/swghosh/DeepFace/releases/download/weights-vggface2-2d-aligned/VGGFace2_DeepFace_weights_val-0.9034.h5.zip'\n",
    "MD5_HASH = '0b21fb70cd6901c96c19ac14c9ea8b89'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_init = tf.random_normal_initializer(mean=0, stddev=0.01)\n",
    "bias_init = tf.constant_initializer(value=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifying_deepface(image_size=IMAGE_SIZE, channels=CHANNELS, num_classes=NUM_CLASSES, learn_rate=LEARN_RATE, momentum=MOMENTUM):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(*image_size, channels), name='I0'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=11, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='C1'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same', name='M2'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=9, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='C3'))\n",
    "    model.add(tf.keras.layers.LocallyConnected2D(filters=16, kernel_size=9, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='L4'))\n",
    "    model.add(tf.keras.layers.LocallyConnected2D(filters=16, kernel_size=7, strides=2,  activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='L5'))\n",
    "    model.add(tf.keras.layers.LocallyConnected2D(filters=16, kernel_size=5, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='L6'))\n",
    "    model.add(tf.keras.layers.Flatten(name='F7'))\n",
    "    model.add(tf.keras.layers.Dense(units=4096, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='F8'))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.5, name='D9'))\n",
    "    model.add(tf.keras.layers.Dense(units=num_classes, activation=tf.nn.softmax, kernel_initializer=wt_init, bias_initializer=bias_init, name='F10'))\n",
    "\n",
    "    sgd_opt = tf.keras.optimizers.SGD(learning_rate=learn_rate, momentum=momentum)\n",
    "    cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    model.compile(optimizer=sgd_opt, loss=cce_loss, metrics=['acc'])\n",
    "    weights = get_weights()\n",
    "    model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights():\n",
    "    filename = 'deepface.zip'\n",
    "    downloaded_file_path = tf.keras.utils.get_file(filename, DOWNLOAD_PATH,\n",
    "        md5_hash=MD5_HASH, extract=True)\n",
    "    downloaded_h5_file = path.join(path.dirname(downloaded_file_path),\n",
    "        path.basename(DOWNLOAD_PATH).rstrip('.zip'))\n",
    "    return downloaded_h5_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "C1 (Conv2D)                  (None, 142, 142, 32)      11648     \n",
      "_________________________________________________________________\n",
      "M2 (MaxPooling2D)            (None, 71, 71, 32)        0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 63, 63, 16)        41488     \n",
      "_________________________________________________________________\n",
      "L4 (LocallyConnected2D)      (None, 55, 55, 16)        62774800  \n",
      "_________________________________________________________________\n",
      "L5 (LocallyConnected2D)      (None, 25, 25, 16)        7850000   \n",
      "_________________________________________________________________\n",
      "L6 (LocallyConnected2D)      (None, 21, 21, 16)        2829456   \n",
      "_________________________________________________________________\n",
      "F7 (Flatten)                 (None, 7056)              0         \n",
      "_________________________________________________________________\n",
      "F8 (Dense)                   (None, 4096)              28905472  \n",
      "_________________________________________________________________\n",
      "D9 (Dropout)                 (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "F10 (Dense)                  (None, 8631)              35361207  \n",
      "=================================================================\n",
      "Total params: 137,774,071\n",
      "Trainable params: 137,774,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = create_classifying_deepface()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import time\n",
    "\n",
    "filename = r\"C:\\Users\\manz616236\\Downloads\\image.jpg\"\n",
    "img = Image.open(filename)\n",
    "img = img.resize(IMAGE_SIZE)\n",
    "img = np.array(img, dtype=np.float32)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "output = model.predict(img)\n",
    "\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "GENERAL_DIR = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\" \n",
    "syn_list =  ['ADNP', 'ANKRD11', 'CDK13', 'DEAF1', 'DYRK1A', 'EHMT1', 'FBXO11','KDVS', 'SON', 'WAC', 'YY1']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layers = [\"C3\", \"L4\", \"L5\", \"L6\"]\n",
    "img_name = [\"patient\", \"control\"]\n",
    "\n",
    "for syn in tqdm(syn_list):\n",
    "    directory = \"heatmaps/{}\".format(syn)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    path_patient = GENERAL_DIR + \"//{}//{}-patients\".format(syn, syn)\n",
    "    path_control = GENERAL_DIR + \"//{}//{}-selected-ID-controls\".format(syn, syn)\n",
    "\n",
    "    patients = [f for f in listdir(path_patient) if \".jpg\" in f]\n",
    "    controls = [f for f in listdir(path_control) if \".jpg\" in f]\n",
    "\n",
    "    for index in range(len(patients)):\n",
    "        patient = [patients[index]]\n",
    "        control = [controls[index]]\n",
    "\n",
    "        fig = plt.figure(figsize=(18, 18))\n",
    "        columns = 2\n",
    "        rows = len(layers) + 1\n",
    "\n",
    "        for i, img_file in enumerate(patient+control):\n",
    "            paths = [path_patient, path_control]\n",
    "            img = cv2.imread(join(paths[i], img_file))\n",
    "            img = cv2.resize(img, (IMAGE_SIZE))               \n",
    "            img_tensor = np.expand_dims(img, axis=0)\n",
    "\n",
    "            fig.add_subplot(rows, columns, i+1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(\"Original image - {}\".format(img_file, img_name[i]))\n",
    "            \n",
    "            for l, name in enumerate(layers): \n",
    "                conv_layer = model.get_layer(name)\n",
    "                heatmap_model = tf.keras.models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "                conv_output, predictions = heatmap_model(img_tensor)\n",
    "\n",
    "                heatmap = np.squeeze(conv_output.numpy())\n",
    "                heatmap = np.sum(heatmap, axis=2)\n",
    "                \n",
    "                if np.max(heatmap)== 0.0 and np.min(heatmap) == 0.0:\n",
    "                    print(np.max(heatmap))\n",
    "                    print(np.min(heatmap))\n",
    "                    print(name, img_name[i])\n",
    "\n",
    "                nr = l * 2 + i + 1 + 2\n",
    "                fig.add_subplot(rows, columns, nr)\n",
    "                plt.imshow(heatmap)\n",
    "                plt.title(\"Heatmap of layer {} - {}\".format(name, img_name[i]))\n",
    "\n",
    "        plt.savefig('heatmaps/{}/heatmap-{}.png'.format(syn, index), bbox_inches='tight')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average heatmap per syndrome\n",
    "layers = [\"C3\", \"L4\", \"L5\", \"L6\"]\n",
    "img_name = [\"patient\", \"control\"]\n",
    "\n",
    "\n",
    "rows, columns = 4, 2\n",
    "\n",
    "for syn in syn_list:\n",
    "    directory = \"heatmaps/{}\".format(syn)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    path_patient = GENERAL_DIR + \"//{}//{}-patients\".format(syn, syn)\n",
    "    path_control = GENERAL_DIR + \"//{}//{}-selected-ID-controls\".format(syn, syn)\n",
    "\n",
    "    patients = [f for f in listdir(path_patient) if \".jpg\" in f]\n",
    "    controls = [f for f in listdir(path_control) if \".jpg\" in f]\n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "    \n",
    "    for l, name in enumerate(layers):\n",
    "\n",
    "        # all patients\n",
    "        conv_layer = model.get_layer(name)\n",
    "        heatmap_model = tf.keras.models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "        all_heatmaps = []\n",
    "        for p in patients:\n",
    "            img = cv2.imread(join(path_patient, p))\n",
    "            img = cv2.resize(img, (IMAGE_SIZE))               \n",
    "            img_tensor = np.expand_dims(img, axis=0)\n",
    "            \n",
    "            conv_output, predictions = heatmap_model(img_tensor)\n",
    "\n",
    "            heatmap = np.squeeze(conv_output.numpy())\n",
    "            heatmap = np.sum(heatmap, axis=2)\n",
    "            \n",
    "            all_heatmaps.append(heatmap)\n",
    "                    \n",
    "        all_heatmaps = np.array(all_heatmaps)\n",
    "        all_heatmaps = np.mean(all_heatmaps, axis=0)\n",
    "        \n",
    "        nr = l * 2 + 1 \n",
    "        fig.add_subplot(rows, columns, nr)\n",
    "        plt.imshow(all_heatmaps)\n",
    "        plt.title(\"Heatmap of layer {}\".format(name))\n",
    "        \n",
    "        \n",
    "        # all controls\n",
    "        conv_layer = model.get_layer(name)\n",
    "        heatmap_model = tf.keras.models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "        all_heatmaps = []\n",
    "        for p in controls:\n",
    "            img = cv2.imread(join(path_control, p))\n",
    "            img = cv2.resize(img, (IMAGE_SIZE))               \n",
    "            img_tensor = np.expand_dims(img, axis=0)\n",
    "            \n",
    "            conv_output, predictions = heatmap_model(img_tensor)\n",
    "\n",
    "            heatmap = np.squeeze(conv_output.numpy())\n",
    "            heatmap = np.sum(heatmap, axis=2)\n",
    "            \n",
    "            all_heatmaps.append(heatmap)\n",
    "                    \n",
    "        all_heatmaps = np.array(all_heatmaps)\n",
    "        all_heatmaps = np.mean(all_heatmaps, axis=0)\n",
    "        \n",
    "        nr = l * 2 + 1 + 1\n",
    "        fig.add_subplot(rows, columns, nr)\n",
    "        plt.imshow(all_heatmaps)\n",
    "        plt.title(\"Heatmap of layer {} control\".format(name))\n",
    "        \n",
    "\n",
    "    plt.savefig('heatmaps/{}/avg-{}.png'.format(syn, syn), bbox_inches='tight')\n",
    "    plt.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
