{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot most important features Random Forest \n",
    "This notebook plots the most important features of Model 3, which is based on a Random Forest. The features, aka the distances which have a combined importance of at least 0.8 are visualized for a randome image for that syndrome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "import numpy as np\n",
    "import csv\n",
    "import itertools\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import figure\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from global_variables import GENERAL_DIR, syn_list, LEFT, RIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rep(syn, syn_csv, ID_csv, data_dir):\n",
    "    \n",
    "    # open directories\n",
    "    syn_dir = data_dir+\"\\\\{}-patients\".format(syn)\n",
    "    ID_dir = data_dir+ \"\\\\{}-selected-ID-controls\".format(syn)\n",
    "\n",
    "    # get list of filenames\n",
    "    files_syn = [f for f in listdir(syn_dir) if (isfile(join(syn_dir, f))) and \".jpg\" in f]\n",
    "    files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f))) and \".jpg\" in f]\n",
    "    \n",
    "    data_syn, data_ID, labels_syn, labels_ID = [], [], [], []\n",
    "    \n",
    "    with open (syn_csv, newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for index, row in enumerate(reader):\n",
    "            if row[0] in files_syn: \n",
    "                rep = list(map(float, row[1:]))\n",
    "                data_syn.append(rep)\n",
    "                labels_syn.append(1)\n",
    "\n",
    "    with open (ID_csv, newline='') as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for index, row in enumerate(reader):\n",
    "            if row[0] in files_ID:\n",
    "                rep = list(map(float, row[1:]))\n",
    "                data_ID.append(rep)\n",
    "                labels_ID.append(0)\n",
    "\n",
    "    return np.array(data_syn), np.array(data_ID), np.array(labels_syn), np.array(labels_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(syn, GENERAL_DIR, data_dir): \n",
    "    \n",
    "    method = \"facereader-landmarks-distances\"\n",
    "    syn_csv = GENERAL_DIR+ \"\\\\features_facereader_landmarks_distances_patient_groups_left_right.csv\"\n",
    "    ID_csv = GENERAL_DIR+ \"\\\\features_facereader_landmarks_distances_all_controls_left_right.csv\"    \n",
    "    data_syn_dis, data_ID_dis, labels_syn_dis, labels_ID_dis = read_rep(syn, syn_csv, ID_csv, data_dir)  \n",
    "        \n",
    "    indices_to_keep = []\n",
    "    \n",
    "    for index, rep in enumerate(data_syn_dis):\n",
    "        if not all(v == 0 for v in data_syn_dis[index]) and not all(v == 0 for v in data_ID_dis[index]):\n",
    "            indices_to_keep.append(index)\n",
    "                  \n",
    "    # only distance with facereader rep\n",
    "    data_syn_dis = data_syn_dis[indices_to_keep]\n",
    "    data_ID_dis = data_ID_dis[indices_to_keep]\n",
    "    data_dis = data_syn_dis.tolist() + data_ID_dis.tolist()\n",
    "    \n",
    "    # labels with facereader rep\n",
    "    labels_syn_dis = labels_syn_dis[indices_to_keep]\n",
    "    labels_ID_dis = labels_ID_dis[indices_to_keep]\n",
    "    labels = labels_syn_dis.tolist() + labels_ID_dis.tolist() \n",
    "\n",
    "    return np.array(data_dis), np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest_classifier(data, labels):\n",
    "\n",
    "    forest = RandomForestClassifier(n_estimators=10,random_state=0) # 10 has been found with best aroc scores\n",
    "    forest.fit(data, labels)\n",
    "    importances = forest.feature_importances_\n",
    "    std = np.std([tree.feature_importances_ for tree in forest.estimators_],axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    for i in range(1, 30):\n",
    "        important_indices = indices[0:i] \n",
    "        importance = sum(importances[important_indices])\n",
    "        if importance >= 0.8:\n",
    "            break\n",
    "            \n",
    "    return important_indices, importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_image(GENERAL_DIR, syn):\n",
    "    \n",
    "    file = GENERAL_DIR+ \"\\\\features_facereader_landmarks_patient_groups.csv\"\n",
    "\n",
    "    # Find random image of syndrome and retrieve keypoints \n",
    "    with open(file, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in reader:\n",
    "            if syn in row[0] and len(row[1:]) > 93:\n",
    "                landmarks_left, landmarks_right = [], []\n",
    "                i = 1\n",
    "                count = 0\n",
    "\n",
    "                while i < len(row[1:]):\n",
    "                    if count in LEFT:\n",
    "                        landmarks_left.append((float(row[i]), float(row[i+1]), float(row[i+2])))\n",
    "                    if count in RIGHT:\n",
    "                        landmarks_right.append((float(row[i]), float(row[i+1]), float(row[i+2])))\n",
    "\n",
    "                    count += 1\n",
    "                    i+=3   \n",
    "\n",
    "                return landmarks_left, landmarks_right, row[0]          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs():\n",
    "    pairs = []\n",
    "    combs = [comb for comb in itertools.combinations([*range(0, len(LEFT))], 2)]\n",
    "    \n",
    "    for comb in combs:\n",
    "        a = comb[0]\n",
    "        b = comb[1]\n",
    "        pairs.append([a, b])\n",
    "        \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_image(landmarks_left, landmarks_right, important_indices, pairs, image_name, nr_feats, importance):\n",
    "    fig = figure(figsize=(6,6))\n",
    "    ax = Axes3D(fig)\n",
    "            \n",
    "    for [x, y, z] in landmarks_left:\n",
    "        ax.scatter(x, y, z, color='b', s=5)\n",
    "    for [x, y, z] in landmarks_right:\n",
    "        ax.scatter(x, y, z, color='b', s=5) \n",
    "            \n",
    "    combs = [comb for comb in itertools.combinations([*range(0, len(LEFT))], 2)]\n",
    "    amount_dis = len(combs)\n",
    "       \n",
    "    for index in important_indices:\n",
    "        if index < amount_dis:\n",
    "            [a, b] = pairs[index]        \n",
    "            [x, y, z] = landmarks_left[a]\n",
    "            [x2, y2, z2] = landmarks_left[b]\n",
    "            ax.plot((x, x2), (y, y2), (z, z2)) \n",
    "        else:          \n",
    "            index = index - amount_dis\n",
    "            [a, b] = pairs[index]        \n",
    "            [x, y, z] = landmarks_right[a]\n",
    "            [x2, y2, z2] = landmarks_right[b]\n",
    "            ax.plot((x, x2), (y, y2), (z, z2)) \n",
    "    \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    title = \"{}: with {} features and {:.3f} importance\".format(image_name, nr_feats, importance)\n",
    "    ax.set_title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "syn = '22q11'   \n",
    "\n",
    "# load all data of this syn \n",
    "data_dir = GENERAL_DIR + \"\\\\{}\".format(syn) \n",
    "data, labels = load_data(syn, GENERAL_DIR, data_dir)\n",
    "data = Normalizer().fit_transform(data)\n",
    "\n",
    "# train complete random forest model and return indices\n",
    "indices, importance = randomforest_classifier(data, labels)\n",
    "landmark_pairs = get_pairs()\n",
    "\n",
    "# get landmarks and image name of a random face\n",
    "landmarks_left, landmarks_right, image_name = random_image(GENERAL_DIR, syn)\n",
    "visualize_image(landmarks_left, landmarks_right, indices, landmark_pairs, image_name, len(indices), importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
