{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying different classifiers on data of KdV patients and ID controls\n",
    "Overview of this notebook:\n",
    "\n",
    "First the deepface representations of the cropped images are read in from an Excel file. The data is then plotted by using either t-sne or PCA for dimension reduction. It is clear that there aren't two clear clusters.\n",
    "\n",
    "In the rest of the notebook the following classifiers are tested: k-NN, SVM, Random Forest, Gradient Boosting, AdaBoost, Gaussian Naive Bayes. In the end also an ensemble of all these methods or some of them is tried. None outperforming the Gradient Boosting classifier. \n",
    "\n",
    "To normalize the data either Normalizer (unit form) or StandardScaler (z = (x - mean)/std) is used, without any specific difference in performance yet.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from sklearn.model_selection import cross_val_score, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import date\n",
    "from os.path import join, isfile\n",
    "from os import listdir\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rep(kdv_csv, ID_csv, low_age, high_age, data_dir):\n",
    "    \n",
    "    # open directories\n",
    "    kdv_dir = data_dir+\"\\\\kdv-patients-age-group-\"+str(low_age) + \"-\" + str(high_age)\n",
    "    ID_dir = data_dir+ \"\\\\kdv-selected-ID-controls-age-group-\"+str(low_age) + \"-\" + str(high_age)\n",
    "\n",
    "    # get list of filenames\n",
    "    files_kdv = [f for f in listdir(kdv_dir) if (isfile(join(kdv_dir, f)) & (\"crop_sized.jpg\" in f))]\n",
    "    files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f)) & (\"crop_sized.JPG\" in f))]\n",
    "    \n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    for i, csv_file in enumerate([ID_csv, kdv_csv]):\n",
    "        with open (csv_file, newline='') as file:\n",
    "            reader = csv.reader(file, delimiter=',')\n",
    "            for row in reader:\n",
    "                if row[0] in files_kdv or row[0] in files_ID:\n",
    "                    rep = list(map(float, row[1:]))\n",
    "                    data.append(rep)\n",
    "                    labels.append(i)\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_tsne(data, labels, lowest_age = -1, highest_age = -1):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot([1,2])\n",
    "\n",
    "    # visualize data in tnse (men/women)\n",
    "    X_embedded_tsne = TSNE(n_components=2, init='pca').fit_transform(data)\n",
    "\n",
    "    plt.subplot(121)\n",
    "    unique = list(set(labels))\n",
    "    colors = [plt.cm.jet(float(i)/max(unique)) for i in unique]\n",
    "    for i, u in enumerate(unique):\n",
    "        xi = [X_embedded_tsne[j, 0] for j  in range(len(X_embedded_tsne[:,0])) if labels[j] == u]\n",
    "        yi = [X_embedded_tsne[j, 1] for j  in range(len(X_embedded_tsne[:,1])) if labels[j] == u]\n",
    "        plt.scatter(xi, yi, c=[colors[i]], label=str(u))\n",
    "    plt.legend()\n",
    "    plt.title(\"t-sne for age range {}-{}\".format(lowest_age, highest_age))\n",
    "\n",
    "    # visualize data in pca (men/women)\n",
    "    X_embedded_pca = PCA(n_components=2).fit_transform(data)\n",
    "\n",
    "    plt.subplot(122)\n",
    "    unique = list(set(labels))\n",
    "    colors = [plt.cm.jet(float(i)/max(unique)) for i in unique]\n",
    "    for i, u in enumerate(unique):\n",
    "        xi = [X_embedded_pca[j, 0] for j  in range(len(X_embedded_pca[:,0])) if labels[j] == u]\n",
    "        yi = [X_embedded_pca[j, 1] for j  in range(len(X_embedded_pca[:,1])) if labels[j] == u]\n",
    "        plt.scatter(xi, yi, c=[colors[i]], label=str(u))\n",
    "    plt.legend()\n",
    "    plt.title(\"pca for age range{}-{}\".format(lowest_age, highest_age))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(y_true, y_pred): \n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "    plt.figure(1, figsize=(12,6))\n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    plt.plot(fpr, tpr, lw=2, alpha=0.5, label='LOOCV ROC (AUC = %0.2f)' % (roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='k', label='Chance level', alpha=.8)\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics_loo(model, data, labels):\n",
    "    all_y, all_probs, all_preds = [], [], [] \n",
    "    loo = LeaveOneOut()\n",
    "    \n",
    "    for train, test in loo.split(data):\n",
    "        all_y.append(labels[test])\n",
    "        model = model.fit(data[train], labels[train])\n",
    "        all_probs.append(model.predict_proba(data[test].reshape(1, -1))[:,1])\n",
    "        all_preds.append(model.predict(data[test].reshape(1, -1)))\n",
    "        \n",
    "    aroc = roc_auc_score(all_y, all_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_y, all_preds).ravel()\n",
    "    spec = tn / (tn+fp)  \n",
    "    sens = tp / (tp+fn) \n",
    "    \n",
    "    return aroc, spec, sens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data, i):\n",
    "\n",
    "    if i == 0:\n",
    "        return data\n",
    "    \n",
    "    if i == 1:\n",
    "        return Normalizer().fit_transform(data)\n",
    "        \n",
    "    if i == 2:\n",
    "        return StandardScaler().fit_transform(data)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gr_classifier_conf_matrix(data, labels, trees, norm):\n",
    "    data = normalize(data, norm)\n",
    "\n",
    "    all_y, all_probs, all_preds = [], [], [] \n",
    "    loo = LeaveOneOut()\n",
    "            \n",
    "    # leave one out split and make prediction\n",
    "    for train, test in tqdm(loo.split(data)):\n",
    "        all_y.append(labels[test])\n",
    "        model = GradientBoostingClassifier(n_estimators=trees)\n",
    "        model = model.fit(data[train], labels[train])\n",
    "        all_probs.append(model.predict_proba(data[test].reshape(1, -1))[:,1])\n",
    "        all_preds.append(model.predict(data[test].reshape(1, -1)))\n",
    "\n",
    "    # based on all predictions make aroc curve and confusion matrix\n",
    "    aroc = roc_auc_score(all_y, all_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_y, all_preds).ravel()\n",
    "    spec = tn / (tn+fp)  \n",
    "    sens = tp / (tp+fn)\n",
    "                                \n",
    "    return tn, fp, fn, tp, aroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate(data_df, labels_df, data_dlib, labels_dlib, data_combination, nr_feats):\n",
    "    # assert data has same shape and labels are exactly the same\n",
    "    assert data_df.shape[0] == data_dlib.shape[0]\n",
    "    assert labels_df.shape == labels_dlib.shape\n",
    "    match = [i == j for i, j in zip(labels_df, labels_dlib)]\n",
    "    assert False not in match\n",
    "                \n",
    "                \n",
    "    if data_combination == 2:\n",
    "        # deepface + dlib (all features) \n",
    "        data, labels  = [], []\n",
    "        for index, (df_i, dlib_i) in enumerate(zip(data_df, data_dlib)):\n",
    "            if len(dlib_i) == 2210: \n",
    "                #only if a face is found (otherwise there a fewer zeros)\n",
    "                data.append(df_i.tolist()+dlib_i) # concatenation of 4096 deepface + 2210 dlib\n",
    "                labels.append(labels_df[index])\n",
    "\n",
    "   \n",
    "    return 0, np.array(data), np.array(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "def main():    \n",
    "\n",
    "    data_dir = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\kdv\" \n",
    "    \n",
    "    low_age = 1\n",
    "    high_age = 40\n",
    "\n",
    "    method = \"dlib\"\n",
    "    kdv_csv = data_dir+\"\\\\representations\\kdv-patients-\"+method+\".csv\"  \n",
    "    ID_csv  = data_dir+\"\\\\representations\\ID-controls-\"+method+\".csv\"\n",
    "    data_dlib, labels_dlib = read_rep(kdv_csv, ID_csv, low_age, high_age, data_dir)\n",
    "\n",
    "    \n",
    "    method = \"deepface\"\n",
    "    kdv_csv = data_dir+\"\\\\representations\\kdv-patients-\"+method+\".csv\"  \n",
    "    ID_csv  = data_dir+\"\\\\representations\\ID-controls-\"+method+\".csv\"\n",
    "    data_df, labels_df = read_rep(kdv_csv, ID_csv, low_age, high_age, data_dir)\n",
    "\n",
    "\n",
    "    # data, labels depend on data_combination\n",
    "    nr_comps, data, labels = concatenate(data_df, labels_df, data_dlib, labels_dlib, 2, 0)\n",
    "\n",
    "    trees = 10\n",
    "    normalize = 2\n",
    "    \n",
    "    tn, fp, fn, tp, aroc = gr_classifier_conf_matrix(data, labels, trees, normalize)\n",
    "    spec = tn / (tn+fp)  \n",
    "    sens = tp / (tp+fn)\n",
    "    print(tn, fp, fn, tp)\n",
    "    print(\"Aroc: {}\".format(aroc))\n",
    "    print(\"Specificity: {}\".format(spec))\n",
    "    print(\"Sensitivity: {}\".format(sens))\n",
    "    \n",
    "    \n",
    "    conf_matrix = [[tp, fp],\n",
    "             [fn, tn]]\n",
    "    df_cm = pd.DataFrame(conf_matrix, index = [\"Kdvs_pred\", \"Control_pred\"],\n",
    "                      columns = [\"Kdvs\", \"Control\"])\n",
    "    plt.figure(figsize = (10,7))\n",
    "    sns_heat = sns.heatmap(df_cm, annot=True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
