{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load weights of DeepFace\n",
    "2. Add classification layer (2)\n",
    "3. For each syn in syn_list calculate the stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from os import path\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image \n",
    "from keras.models import Model\n",
    "import tensorflow\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import keras.initializers\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import cv2\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (152, 152) # set by the model \n",
    "CHANNELS = 3 # RGB image\n",
    "NUM_CLASSES = 8631 # classification layer will be removed \n",
    "LEARN_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "DOWNLOAD_PATH = 'https://github.com/swghosh/DeepFace/releases/download/weights-vggface2-2d-aligned/VGGFace2_DeepFace_weights_val-0.9034.h5.zip'\n",
    "MD5_HASH = '0b21fb70cd6901c96c19ac14c9ea8b89'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifying_deepface(image_size=IMAGE_SIZE, channels=CHANNELS, num_classes=NUM_CLASSES, learn_rate=LEARN_RATE, momentum=MOMENTUM):\n",
    "    \"\"\"\n",
    "    Deep CNN architecture primarily for Face Recognition,\n",
    "    Face Verification and Face Representation (feature extraction) purposes\n",
    "    \"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\"\n",
    "    CNN architecture proposed by Taigman et al. (CVPR 2014)\n",
    "    \"\"\"\n",
    "\n",
    "    wt_init = keras.initializers.RandomNormal(mean=0, stddev=0.01)\n",
    "    bias_init = keras.initializers.Constant(value=0.5)\n",
    "\n",
    "    \"\"\"\n",
    "    Construct certain functions \n",
    "    for using some common parameters\n",
    "    with network layers\n",
    "    \"\"\"\n",
    "    def conv2d_layer(**args):\n",
    "        return keras.layers.Conv2D(**args, \n",
    "            kernel_initializer=wt_init, \n",
    "            bias_initializer=bias_init,\n",
    "            activation=keras.activations.relu)\n",
    "    def lc2d_layer(**args):\n",
    "        return keras.layers.LocallyConnected2D(**args, \n",
    "            kernel_initializer=wt_init, \n",
    "            bias_initializer=bias_init,\n",
    "            activation=keras.activations.relu)\n",
    "    def dense_layer(**args):\n",
    "        return keras.layers.Dense(**args, \n",
    "            kernel_initializer=wt_init, \n",
    "            bias_initializer=bias_init)\n",
    "\n",
    "    \"\"\"\n",
    "    Create the network using\n",
    "    tf.keras.layers.Layer(s)\n",
    "    \"\"\"\n",
    "    deepface = keras.models.Sequential([\n",
    "        keras.layers.InputLayer(input_shape=(*image_size, channels), name='I0'),\n",
    "        conv2d_layer(filters=32, kernel_size=11, name='C1'),\n",
    "        keras.layers.MaxPooling2D(pool_size=3, strides=2, padding='same',  name='M2'),\n",
    "        conv2d_layer(filters=16, kernel_size=9, name='C3'),\n",
    "        lc2d_layer(filters=16, kernel_size=9, name='L4'),\n",
    "        lc2d_layer(filters=16, kernel_size=7, strides=2, name='L5'),\n",
    "        lc2d_layer(filters=16, kernel_size=5, name='L6'),\n",
    "        keras.layers.Flatten(name='F0'),\n",
    "        dense_layer(units=4096, activation=keras.activations.relu, name='F7'),\n",
    "        keras.layers.Dropout(rate=0.5, name='D0'),\n",
    "        dense_layer(units=num_classes, activation=keras.activations.softmax, name='F8')\n",
    "    ], name='DeepFace')\n",
    "    # deepface.summary()\n",
    "\n",
    "    \"\"\"\n",
    "    A tf.keras.optimizers.SGD will\n",
    "    be used for training,\n",
    "    and compile the model\n",
    "    \"\"\"\n",
    "    sgd_opt = keras.optimizers.SGD(lr=learn_rate, momentum=momentum)\n",
    "    cce_loss = keras.losses.categorical_crossentropy\n",
    "\n",
    "    deepface.compile(optimizer=sgd_opt, loss=cce_loss, metrics=['accuracy'])\n",
    "    \n",
    "    return deepface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights():\n",
    "    filename = 'deepface.zip'\n",
    "    downloaded_file_path = keras.utils.get_file(filename, DOWNLOAD_PATH, \n",
    "        md5_hash=MD5_HASH, extract=True)\n",
    "    downloaded_h5_file = path.join(path.dirname(downloaded_file_path), \n",
    "        path.basename(DOWNLOAD_PATH).rstrip('.zip'))\n",
    "    return downloaded_h5_file\n",
    "\n",
    "\n",
    "def create_deepface():\n",
    "    model = create_classifying_deepface()\n",
    "    weights = get_weights()\n",
    "    model.load_weights(weights)\n",
    "    \n",
    "    x = model.layers[-2].output\n",
    "    x = Dense(2, activation='softmax', name='predictions')(x)\n",
    "    model2 = Model(model.input, x)\n",
    "    \n",
    "    return model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(syn, GENERAL_DIR):\n",
    "    \n",
    "    data, labels = [], [] \n",
    "    \n",
    "    syn_dir = GENERAL_DIR + \"\\\\{}\\{}-patients\".format(syn, syn)\n",
    "    ID_dir = GENERAL_DIR + \"\\\\{}\\{}-selected-ID-controls\".format(syn, syn)\n",
    "\n",
    "    # get list of filenames\n",
    "    files_syn = [f for f in listdir(syn_dir) if (isfile(join(syn_dir, f)))and \".jpg\" in f]\n",
    "    files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f))) and \".jpg\" in f]\n",
    "    \n",
    "    print(\"Syn_list: {}, ID_list: {}\".format(len(files_syn), len(files_ID)))\n",
    "\n",
    "    for filename in files_syn:\n",
    "        im = Image.open(join(syn_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        data.append(im)\n",
    "        labels.append(1)\n",
    "\n",
    "    for filename in files_ID:\n",
    "        im = Image.open(join(ID_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        data.append(im)\n",
    "        labels.append(0)    \n",
    "    \n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Het systeem kan het opgegeven pad niet vinden: 'H:\\\\Genetica Projecten\\\\Facial Recognition\\\\Studenten en Onderzoekers\\\\Fien\\\\ADNP\\\\ADNP-patients'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-08004b6514e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msyn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msyn_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGENERAL_DIR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mresults_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Syndrome {} with {} patients and {} controls\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-1554d7f8db8a>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(syn, GENERAL_DIR)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# get list of filenames\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mfiles_syn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyn_dir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msyn_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;32mand\u001b[0m \u001b[1;34m\".jpg\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mfiles_ID\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mf\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID_dir\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mID_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\".jpg\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Het systeem kan het opgegeven pad niet vinden: 'H:\\\\Genetica Projecten\\\\Facial Recognition\\\\Studenten en Onderzoekers\\\\Fien\\\\ADNP\\\\ADNP-patients'"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 16\n",
    "GENERAL_DIR = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\" \n",
    "\n",
    "# load img data\n",
    "\n",
    "\n",
    "syn_list = ['ADNP', 'ANKRD11', 'CDK13', 'DEAF1', 'DYRK1A', 'EHMT1', 'FBXO11', 'SON', 'WAC', 'YY1', 'KDVS']\n",
    "results_file = open(\"results/deepface_classification.txt\", \"w\")\n",
    "\n",
    "for syn in syn_list:\n",
    "    data, labels = load_data(syn, GENERAL_DIR)\n",
    "\n",
    "    results_file.write(\"Syndrome {} with {} patients and {} controls\\n\".format(syn, labels.tolist().count(1), labels.tolist().count(0)))\n",
    "    all_y, all_probs, all_preds = [], [], [] \n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    for train_index, test_index in tqdm(loo.split(data)):\n",
    "        X_train, X_test = np.array(data[train_index]), data[test_index]\n",
    "        y_train, y_test = np.array(labels[train_index]), labels[test_index]\n",
    "\n",
    "        model = create_deepface()\n",
    "        model.fit(x=X_train, y=y_train, batch_size=BATCH_SIZE, epochs=10, shuffle=True)\n",
    "\n",
    "        y_pred_array = model.predict(X_test)\n",
    "        y_pred = tf.math.argmax(y_pred_array, -1).numpy()\n",
    "\n",
    "        all_y.append(y_test[0])\n",
    "        all_probs.append(y_pred_array[0][1])\n",
    "        all_preds.append(y_pred) \n",
    "\n",
    "    aroc = roc_auc_score(all_y, all_probs)\n",
    "    tn, fp, fn, tp = confusion_matrix(all_y, all_preds).ravel()\n",
    "    spec = tn / (tn+fp)  \n",
    "    sens = tp / (tp+fn)\n",
    "\n",
    "    results_file.write(\"AROC: {:.4f}, spec: {:.4f}, sens: {:.4f}\\n\\n\".format(aroc, spec, sens))\n",
    "    \n",
    "    break\n",
    "    \n",
    "results_file.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def deepface_reps(GENERAL_DIR, syn_name):\n",
    "\n",
    "    model = create_deepface()\n",
    "    syn_rep, ID_rep = [], []\n",
    "\n",
    "    syn_dir = GENERAL_DIR + \"\\\\{}\\{}-patients\".format(syn_name, syn_name)\n",
    "    ID_dir = GENERAL_DIR + \"\\\\{}\\{}-selected-ID-controls\".format(syn_name, syn_name)\n",
    "\n",
    "    # get list of filenames\n",
    "    files_syn = [f for f in listdir(syn_dir) if (isfile(join(syn_dir, f)))and syn_name in f]\n",
    "    files_ID = [f for f in listdir(ID_dir) if (isfile(join(ID_dir, f))) and \".jpg\" in f]\n",
    "    \n",
    "    print(\"Syn_list: {}, ID_list: {}\".format(len(files_syn), len(files_ID)))\n",
    "\n",
    "        \n",
    "    # for each kdv image save deepface rep as list:\n",
    "    for filename in files_syn:\n",
    "        im = Image.open(join(syn_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        output = model.predict(np.expand_dims(im, axis=0))\n",
    "        syn_rep.append([filename] + output[0].tolist())  \n",
    "\n",
    "\n",
    "    # for each ID image save deepface rep as list:\n",
    "    for filename in files_ID:\n",
    "        im = Image.open(join(ID_dir, filename))\n",
    "        im = im.resize(IMAGE_SIZE)\n",
    "        output = model.predict(np.expand_dims(im, axis=0))\n",
    "        ID_rep.append([filename] + output[0].tolist())\n",
    "\n",
    "    print(\"Syn_reps: {}, ID_reps: {}\".format(len(syn_rep), len(ID_rep)))\n",
    "\n",
    "    # location to save representation\n",
    "    csv_file_syn = GENERAL_DIR + \"\\\\{}\\\\representations\\\\{}-patients-deepface.csv\".format(syn_name, syn_name)\n",
    "    csv_file_ID = GENERAL_DIR + \"\\\\{}\\\\representations\\\\ID-controls-deepface.csv\".format(syn_name)\n",
    "    \n",
    "    # save representation of kdv patients\n",
    "    with open(csv_file_syn, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(syn_rep)\n",
    "\n",
    "    # save representation of ID controls\n",
    "    with open(csv_file_ID, \"w\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(ID_rep)\n",
    "\n",
    "    print(\"Done with saving all deepface representations for {}.\".format(syn_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
