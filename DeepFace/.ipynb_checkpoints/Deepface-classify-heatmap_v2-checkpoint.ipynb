{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from os import path, listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "from keras.models import Model\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.initializers\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import cv2\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(tf.__version__) # 2.0.0\n",
    "print(keras.__version__) # 2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (152, 152) # set by the model\n",
    "CHANNELS = 3 # RGB image\n",
    "NUM_CLASSES = 8631 # classification layer will be removed\n",
    "LEARN_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "DOWNLOAD_PATH = 'https://github.com/swghosh/DeepFace/releases/download/weights-vggface2-2d-aligned/VGGFace2_DeepFace_weights_val-0.9034.h5.zip'\n",
    "MD5_HASH = '0b21fb70cd6901c96c19ac14c9ea8b89'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wt_init = tf.random_normal_initializer(mean=0, stddev=0.01)\n",
    "bias_init = tf.constant_initializer(value=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_classifying_deepface(image_size=IMAGE_SIZE, channels=CHANNELS, num_classes=NUM_CLASSES, learn_rate=LEARN_RATE, momentum=MOMENTUM):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=(*image_size, channels), name='I0'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=11, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='C1'))\n",
    "    model.add(tf.keras.layers.MaxPool2D(pool_size=(3,3), strides=2, padding='same', name='M2'))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=16, kernel_size=9, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='C3'))\n",
    "    model.add(tf.keras.layers.LocallyConnected2D(filters=16, kernel_size=9, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='L4'))\n",
    "    model.add(tf.keras.layers.LocallyConnected2D(filters=16, kernel_size=7, strides=2,  activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='L5'))\n",
    "    model.add(tf.keras.layers.LocallyConnected2D(filters=16, kernel_size=5, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='L6'))\n",
    "    model.add(tf.keras.layers.Flatten(name='F7'))\n",
    "    model.add(tf.keras.layers.Dense(units=4096, activation=tf.nn.relu, kernel_initializer=wt_init, bias_initializer=bias_init, name='F8'))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.5, name='D9'))\n",
    "    model.add(tf.keras.layers.Dense(units=num_classes, activation=tf.nn.softmax, kernel_initializer=wt_init, bias_initializer=bias_init, name='F10'))\n",
    "\n",
    "    sgd_opt = tf.keras.optimizers.SGD(learning_rate=learn_rate, momentum=momentum)\n",
    "    cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    model.compile(optimizer=sgd_opt, loss=cce_loss, metrics=['acc'])\n",
    "    weights = get_weights()\n",
    "    model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights():\n",
    "    filename = 'deepface.zip'\n",
    "    downloaded_file_path = keras.utils.get_file(filename, DOWNLOAD_PATH,\n",
    "        md5_hash=MD5_HASH, extract=True)\n",
    "    downloaded_h5_file = path.join(path.dirname(downloaded_file_path),\n",
    "        path.basename(DOWNLOAD_PATH).rstrip('.zip'))\n",
    "    return downloaded_h5_file\n",
    "\n",
    "\n",
    "def create_deepface():\n",
    "    model = create_classifying_deepface()\n",
    "    \n",
    "#     model2 = tf.keras.Sequential()\n",
    "\n",
    "#     # remove last dropout layer and dense layer\n",
    "#     for layer in model.layers[:-2]:\n",
    "#         model2.add(layer)\n",
    "\n",
    "#     sgd_opt = tf.keras.optimizers.SGD(learning_rate=LEARN_RATE, momentum=MOMENTUM)\n",
    "#     cce_loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "#     model2.compile(optimizer=sgd_opt, loss=cce_loss, metrics=['acc'])\n",
    "#     model2.build((None, *IMAGE_SIZE, CHANNELS))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "C1 (Conv2D)                  (None, 142, 142, 32)      11648     \n",
      "_________________________________________________________________\n",
      "M2 (MaxPooling2D)            (None, 71, 71, 32)        0         \n",
      "_________________________________________________________________\n",
      "C3 (Conv2D)                  (None, 63, 63, 16)        41488     \n",
      "_________________________________________________________________\n",
      "L4 (LocallyConnected2D)      (None, 55, 55, 16)        62774800  \n",
      "_________________________________________________________________\n",
      "L5 (LocallyConnected2D)      (None, 25, 25, 16)        7850000   \n",
      "_________________________________________________________________\n",
      "L6 (LocallyConnected2D)      (None, 21, 21, 16)        2829456   \n",
      "_________________________________________________________________\n",
      "F7 (Flatten)                 (None, 7056)              0         \n",
      "_________________________________________________________________\n",
      "F8 (Dense)                   (None, 4096)              28905472  \n",
      "_________________________________________________________________\n",
      "D9 (Dropout)                 (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "F10 (Dense)                  (None, 8631)              35361207  \n",
      "=================================================================\n",
      "Total params: 137,774,071\n",
      "Trainable params: 137,774,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = create_deepface()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from datetime import time\n",
    "\n",
    "filename = r\"C:\\Users\\manz616236\\Downloads\\image.jpg\"\n",
    "img = Image.open(filename)\n",
    "img = img.resize(IMAGE_SIZE)\n",
    "img = np.array(img, dtype=np.float32)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "output = model.predict(img)\n",
    "\n",
    "print(output.shape)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_patient = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\ADNP\\ADNP-patients\"\n",
    "patients = [join(path_patient, f) for f in listdir(path_patient)]\n",
    "#patients = [patients[0]]\n",
    "\n",
    "path_control = r\"H:\\Genetica Projecten\\Facial Recognition\\Studenten en Onderzoekers\\Fien\\ADNP\\ADNP-selected-ID-controls\"\n",
    "controls = [join(path_control, f) for f in listdir(path_control)]\n",
    "#controls = [controls[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "layers = [\"C3\", \"L4\", \"L5\", \"L6\"]\n",
    "\n",
    "\n",
    "\n",
    "for index in range(len(patients)):\n",
    "    print(index)\n",
    "    patient = [patients[index]]\n",
    "    control = [controls[index]]\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    columns = 2\n",
    "    rows = len(layers)*len(patients)\n",
    "    \n",
    "    for i, img in enumerate(patient+control):\n",
    "\n",
    "        img = Image.open(img)\n",
    "        img = np.array(img.resize(IMAGE_SIZE), dtype=np.float32)\n",
    "        img_tensor = np.expand_dims(img, axis=0)\n",
    "        for l, name in enumerate(layers): \n",
    "\n",
    "            conv_layer = model.get_layer(name)\n",
    "\n",
    "            heatmap_model = models.Model([model.inputs], [conv_layer.output, model.output])\n",
    "\n",
    "            # Get gradient of the winner class w.r.t. the output of the (last) conv. layer\n",
    "            with tf.GradientTape() as gtape:\n",
    "                conv_output, predictions = heatmap_model(img_tensor)\n",
    "                loss = predictions[:, np.argmax(predictions[0])]\n",
    "                grads = gtape.gradient(loss, conv_output)\n",
    "                pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "            heatmap = tf.reduce_mean(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
    "            heatmap = np.maximum(heatmap, 0)\n",
    "            max_heat = np.max(heatmap)\n",
    "            if max_heat == 0:\n",
    "                max_heat = 1e-10\n",
    "            heatmap /= max_heat\n",
    "\n",
    "            heatmap = np.squeeze(heatmap)\n",
    "\n",
    "            nr = l * 2 + i + 1\n",
    "            fig.add_subplot(rows, columns, nr)\n",
    "            plt.imshow(heatmap)\n",
    "            plt.title(\"Heatmap of layer {}\".format(name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
